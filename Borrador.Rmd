---
title: "Borrador"
author: "Jennifer Salazar"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Falta hacer esto

Defina la variable de la serie, su unidad de medida, su construcci√≥n e interpretacion de sus cifras, perƒ±odos observados, frecuencia de observacion, total de observaciones y fuente de los datos.



# Librerias utiles

```{r}
library(forecast)
library(TSA)
library(fANCOVA)

```

```{r}
Datos20=read.table("anex-EMMET-dic2019-Fabricacion de otros productos quimicos (1).csv",header=T,sep=";",skip=14,dec=",",colClasses=c(rep("NULL",4),"numeric",rep("NULL",6)))
Datos20=ts(Datos20,freq=12,start=c(2001,1))
```



# An√°lisis descriptivo:

Se Consideran los datos sobre el √≠ndice de producci√≥n nominal de la clase otros productos quimicos sector de manufactura, de enero de 2001 a diciembre de 2019
(N=228), a√±o base 2018. Ver Figura 1(a).


## Descomposici√≥n aditiva (tendencia)

```{r}
Tt=decompose(Datos20)$trend
```


```{r}
par(mfrow=c(1,2))
plot(Datos20, sub="(a)", lwd=1.5)
grid()
plot(Tt,ylim=c(min(Datos20),max(Datos20)), sub="(b)", lwd=1.5, ylab=expression(T[t]))
grid()
```


**Figura 1.**  (a) √çndice de producci√≥n nominal de en Colombia sector manufactura,
Clase industrial: otros productos quimicos. Enero 2001 - diciembre 2019; (b) Tendencia seg√∫n el filtro de descomposici√≥n aditiva.


De la Figura 1(a) se deduce la presencia de estacionalidad y tendencia aditivas,  es aditiva dado que su varianza es constante alrededor de su trayectoria de largo plazo(tendencia). En la Figura 1(b) es visible que la serie es de tendencia creciente y que existen ciclos. 


##  grafico de boxplots comparativos de la distribucion de la serie versus perƒ±odos del a√±o calendario

## Periodograma

```{r}
par(mfrow=c(2,2))
boxplot(Datos20~cycle(Datos20), names=month.abb, ylab="Producci√≥n nominal", xlab = "Meses del a√±o", sub="(a)")
grid()
periodogram(diff(Datos20),lwd=4, sub="(b)") #periodograma sobre los logaritmos diferenciados
abline(v=c(1:6)/12,col=2,lty=2)
grid()
```


**Figura 2.** (a) Boxplots: distribuci√≥n por meses de la serie. (b) Periodograma
sobre las diferencias de la serie.

De la figura 2(a) en los boxplots comparativos se ve c√≥mo la media (o mediana) de la distribuci√≥n de la serie seg√∫n el periodo del a√±o, cambia a lo largo de un a√±o calendario siendo menor en los meses de enero, febrero, abril y diciembre comparados con el resto del a√±o. Tiene un crecimiento de enero a marzo y luego vuelve y baja en abril  para volver a subir en mayo manteniendose relativamente al mismo nivel en los siguientes meses hasta noviembre, para luego decaer en diciembre y retormar el siguiente a√±o; se confirma que existe un patr√≥n peri√≥dico anual con una forma constante en el tiempo.




De la figura 2(b) Periodograma: muestra la asociacion de la serie con cinco componentes periodicas (valor alto del periodograma en esas frecuencias): en las frecuencias 1/12 y 2/12, 3/12, 4/12, 6/12. El periodograma reafirma la existencia de componente estacional.

# justifique por que existe componente estacional y si su forma es constante o no en el tiempo. 

- Mediante el gr√°fico de la serie vs el tiempo se ve un patr√≥n que se repite cada a√±o; pues en cada a√±o se observa que en los meses del inicio y del final el √≠ndice de producci√≥n nominal es bajo y tiene aproximadamente 2 picos de decaimiento en el transcurso del a√±o.

- Dado que en el gr√°fico de boxplot al menos una de las medias de los meses cambia respecto al resto de los meses del a√±o calendario, por lo tanto se concluye que cada periodo en que se divide el a√±o calendario determina una estaci√≥n, la cual tiene incidencia sobre el valor medio de la serie, por ellos se dice que existe la componente estacional.

- Mediante el periodograma se resalta que hay una asociaci√≥n de la serie con fenomenos periodicos, indicando la existencia de una componente estacional.


## Es la estacionalidad constante o no en el tiempo:

```{r}
par(mfrow=c(2,2))
plot(Datos20, xlim=c(2001,2005))
grid()
plot(Datos20, xlim=c(2006,2010))
grid()
plot(Datos20, xlim=c(2011,2015))
grid()
plot(Datos20, xlim=c(2016,2019))
grid()

```


## la tendencia se puede ajustar globalmente o si es local.

- La tendencia de la serie es global ya que se puede ajustar una curva suave creciente en todos los tiempos de la serie, Tambi√©n se puede ajustar modelos locales para comparar los ajustes y pronosticos respecto a la ajuste global.



##  identificacion de posibles ciclos y cambios estructurales.

* Hay presencia de ciclos en la serie a tr√°ves del tiempo ya que al aplicar la descomposici√≥n aditiva y obtener la tendencia, no se observa una curva suave que describa la tendencia de la serie.
* Hay aproximadamente entre 4 y 5 ciclos en la serie a trav√©s del tiempo (monta√±as).
* Parace haber posible cambio estructural en la serie en el 2015 ya que el nivel de la serie cambia un poco a partir de ese a√±o.




#################################################################################


# Modelos propuestos


Por el an√°lisis descriptivo, para los modelos globales la tendencia puede ser ajustada por un polinomio de grado $p = 2, 3$ y la componente estacional puede representarse como un factor y por tanto usar  variables indicadoras en los modelos globales. Se proponen los siguientes modelos de regresi√≥n, donde t es el √≠ndice de tiempo y $I_{i,t}$ es la indicadora del trimestre i en el tiempo t.


$$\text{Tabla 1. Ecuaci√≥n de los modelos propuestos}$$
$$\begin{array}{|c|}
\hline
\text{ Modelo 1: Modelo cuadr√°tico estacional con indicadoras, mes de referencia diciembre}\\
Y_t=\beta_0+\beta_1t+\beta_2t^2+\sum_{i=1}^{11}\delta_iI_{i,t}+E_t, ~~~ E_t \sim iid N(0, \sigma^2)\\
\hline
\text{Modelo 2: Modelo c√∫bico estacional con indicadoras, mes de referencia diciembre}\\
Y_t=\beta_0+\beta_1t+\beta_2t^2+\beta_3t^3+\sum_{i=1}^{11}\delta_iI_{i,t}+E_t, ~~~ E_t \sim iid N(0, \sigma^2)\\
\hline
\text{Modelos 3: Descomposici√≥n aditiva & Loess cuadr√°tico}\\
\text{En la vecindad de un tiempo} ~t_k~ \text{donde se quiere ajustar} 
Y_t = \beta_{0,k} + \beta_{1,k}t + \beta_{2,k}t^2 + \sum_{i=1}^{12}\delta_i I_{i,t} +  E_t, ~~ E_t \sim iid N(0,\sigma^2) \\
\text{para todo t vecino a} ~~t_k,~~ \text{con} \sum_{i=1}^{12}\delta_i=0,~~~ \beta_{0,k},~\beta_{1,k}~y~\beta_{2,k}~~ \text{los par√°metros de la par√°bola local en la vecindad de} ~~t_k\\
\hline
\text{Modelo 4: Suavizamiento exponencial Holt-Winters aditivo}\\
Y_{t+h} = \beta_{0,t} + \beta_{1,t}\times h + \sum_{i=1}^{12}\delta_{i,t} I_{i,t+h} +  E_{t+h}, ~~ E_t \sim iid N(0,\sigma^2),\text{con} \sum_{i=1}^{12}\delta_{i,t}=0,~~\beta_{0,t}~y~\beta_{1,t}~y~\delta_{i,t}, \text{el nivel en} ~~t,~~\\
\text{la pendiente en} ~~t~~ \text{y los efectos estacionales en t, respectivamente, cambiando lentamente en el tiempo.}\\
\hline
\end{array}$$


## Modelo 1: Modelo cuadr√°tico estacional con indicadoras, mes de referencia diciembre

$$Y_t=\beta_0+\beta_1t+\beta_2t^2+\sum_{i=1}^{11}\delta_iI_{i,t}+E_t, ~~~ E_t \sim iid N(0, \sigma^2)$$

## Modelo 2: Modelo c√∫bico estacional con indicadoras, mes de referencia diciembre

$$Y_t=\beta_0+\beta_1t+\beta_2t^2+\beta_3t^3+\sum_{i=1}^{11}\delta_iI_{i,t}+E_t, ~~~ E_t \sim iid N(0, \sigma^2)$$

## Modelos 3: Descomposici√≥n aditiva & Loess cuadr√°tico

En la vecindad de un tiempo $t_k$ donde se quiere ajustar, $Y_t = \beta_{0,k} + \beta_{1,k}t + \beta_{2,k}t^2 + \sum_{i=1}^{12}\delta_i I_{i,t} +  E_t, ~~ E_t \sim iid N(0,\sigma^2)$ para todo t vecino a $t_k$, con $\sum_{i=1}^{12}\delta_i=0,~~~ \beta_{0,k},~\beta_{1,k}~y~\beta_{2,k}$ los parametros de la parabola local en la vecindad de $t_k$


## Modelo 4: Suavizamiento exponencial Holt-Winters aditivo

$Y_{t+h} = \beta_{0,t} + \beta_{1,t}\times h + \sum_{i=1}^{12}\delta_{i,t} I_{i,t+h} +  E_{t+h}, ~~ E_t \sim iid N(0,\sigma^2)$, con $\sum_{i=1}^{12}\delta_{i,t}=0,~~\beta_{0,t}~y~\beta_{1,t}~y~\delta_{i,t}$, el nivel en $t$, la pendiente en $t$ y los efectos estacionales en $t$, respectivamente, cambiando lentamente en el tiempo.


# Ajustes

## Ajuste de los modelos con validaci√≥n cruzada

Se implementa la estrategia de validaci√≥n cruzada excluyendo del ajuste los √∫ltimos $m = 12$ datos, que comprende de enero de 2001 a diciembre de 2018 por tanto, la validaci√≥n cruzada se har√° con los pron√≥sticos ex-post de estos √∫ltimos.



```{r}
m <- 12 # numero de periodos a pronosticar dentro de la muestra
n <-length(Datos20)-m # tama√±o de la muestra para el ajuste
t <- 1:n #Indice de tiempo en los periodos de ajuste
```


* Datos para el ajuste:

```{r}
yt <- ts(Datos20[t], frequency = 12, start=c(2001, 1))
```



* Creaci√≥n de las variables indicadoras para los datos de muestra
```{r}
mes <- seasonaldummy(yt) #Matriz con las 11 primeras variables Indicadoras mes


#Separando una a una las 11 variables indicadoras

I1 <- mes[,1]
I2 <- mes[,2]
I3 <- mes[,3]
I4 <- mes[,4]
I5 <- mes[,5]
I6 <- mes[,6]
I7 <- mes[,7]
I8 <- mes[,8]
I9 <- mes[,9]
I10 <- mes[,10]
I11 <- mes[,11]
```


* Creaci√≥n de las variables indicadoras para los datos de validaci√≥n cruzada


```{r}
tnuevo <- (n+1):length(Datos20)
ytnuevo <- ts(Datos20[tnuevo], frequency = 12, start = c(2019, 1))


mesnuevo <- seasonaldummy(yt, h=12)
#Separando una a una las 11 indicadoras para los tiempos de pron?stico
I1n=mesnuevo[,1]
I2n=mesnuevo[,2]
I3n=mesnuevo[,3]
I4n=mesnuevo[,4]
I5n=mesnuevo[,5]
I6n=mesnuevo[,6]
I7n=mesnuevo[,7]
I8n=mesnuevo[,8]
I9n=mesnuevo[,9]
I10n=mesnuevo[,10]
I11n=mesnuevo[,11]
```



## Ajuste del modelo 1 Modelo cuadr√°tico estacional con indicadoras


```{r}
mod1 <- lm(yt~t+I(t^2)+I1+I2+I3+I4+I5+I6+I7+I8+I9+I10+I11)
summary(mod1)
```


$$\begin{array}{| c | c | c | c| c |}
\hline
Parametro&Estimaci√≥n&Error~Est√°ndar&T_0&P(|T_{202}|>|T_0|)\\
\hline
\beta_0&35.8242551&1.2250562&29.242949&0.0000000\\
\beta_1&0.1319807&0.0174478&7.564309&0.0000000\\
\beta_2&0.0007051&0.0000779&9.055350&0.0000000\\
\delta_1&-3.1817818&1.3273503&-2.397093&0.0174368\\
\delta_2&5.3069465&1.3272009&3.998601&0.0000893\\
\delta_3&12.0220423&1.3270660&9.059114&0.0000000\\
\delta_4&7.2690612&1.3269454&5.478041&0.0000001\\
\delta_5&12.1146698&1.3268389&9.130475&0.0000000\\
\delta_6&9.8255350&1.3267465&7.405736&0.0000000\\
\delta_7&8.4294343&1.3266681&6.353838&0.0000000\\
\delta_8&9.0930346&1.3266037&6.854372&0.0000000\\
\delta_9&12.5163357&1.3265533&9.435230&0.0000000\\
\delta_{10}&10.5493377&1.3265171&7.952659&0.0000000\\
\delta_{11}&8.9475962&1.3264952&6.745291&0.0000000\\
\hline
\end{array}$$





## Ajuste del modelo 2 Modelo c√∫bico estacional con indicadoras


```{r}
mod2 <- lm(yt~t+I(t^2)+I(t^3)+I1+I2+I3+I4+I5+I6+I7+I8+I9+I10+I11)
summary(mod2)
```


$$\begin{array}{| c | c | c | c| c |}
\hline
Par√°metro&Estimaci√≥n&Error~Est√°ndar&T_0 &P(|T_{201}|>|T_0|)\\
\hline
\beta_0&35.1122117&1.4518673&24.1841735&0.0000000\\
\beta_1&0.1689800&0.0440540&3.8357445&0.0001675\\
\beta_2&0.0002800&0.0004712&0.5943651&0.5529364\\
\beta_3&0.0000013&0.0000014&0.9147258&0.3614316\\
\delta_1&-3.1146344&1.3299145&-2.3419809&0.0201603\\
\delta_2&5.3679308&1.3294103&4.0378283&0.0000767\\
\delta_3&12.0768988&1.3289564&9.0875055&0.0000000\\
\delta_4&7.3178173&1.3285516&5.5081165&0.0000001\\
\delta_5&12.1573451&1.3281951&9.1532824&0.0000000\\
\delta_6&9.8621412&1.3278862&7.4269474&0.0000000\\
\delta_7&8.4599754&1.3276245&6.3722651&0.0000000\\
\delta_8&9.1175066&1.3274098&6.8686450&0.0000000\\
\delta_9&12.5347270&1.3272421&9.4441906&0.0000000\\
\delta_10&10.5616286&1.3271216&7.9582979&0.0000000\\
\delta_11&8.9537593&1.3270487&6.7471217&0.0000000\\
\hline
\end{array}$$



## Funciones a utilizar:

```{r}
#Creando funci√≥n para extraer correctamente estimaciones de los efectos estacionales ùúπùíä por filtro de descomposici√≥n
factoresdeltai=function(descom,s,estacionini){
if(estacionini==1){
deltasi=descom$figure
}
if(estacionini!=1){
j=estacionini;deltasi=c(descom$figure[(s-j+2):s],descom$figure[1:(s-j+1)])
}
deltasi
}
```


## Ajuste modelo 3 Descomposici√≥n aditiva & Loess cuadr√°tico


```{r}
#Descomposici√≥n aditiva de la serie recortada
descom=decompose(yt,type="additive")
```



```{r}
s=12 #Longitud del periodo estacional
```



```{r}
#Componente estacional estimada de la descomposici√≥n de la serie recortada
St=descom$seasonal


deltas_i=factoresdeltai(descom=descom,s=12,estacionini=1) #Obteniendo los s factores estacionales estimados


#el per√≠odo es s=12 y la serie arranca en estaci√≥n 1
deltas <- data.frame(deltas_i)

```

En la Tabla se muestra la estimaci√≥n de los efectos estacionales de acuerdo al filtro de la descomposici√≥n aditiva sobre los primeros 216 datos

$$\begin{array}{| c | c | c | c| c |}
\hline
i& \hat{\delta}_i\\
\hline
1&-10.8780433\\
2&-2.3143178\\
3&4.3650940\\
4&-0.5319649\\
5&4.3979371\\
6&2.0783292\\
7&0.7969567\\
8&1.2373979\\
9&4.6148489\\
10&2.5229371\\
11&1.0633783\\
12&-7.3525531\\
\hline
suma & 0\\
\hline
\end{array}$$



```{r}
#Pron√≥sticos para la componente estacional usando estimaciones del filtro de descomposici√≥n cl√°sica

#los pron√≥sticos inician en enero 2019 y terminan en diciembre 2019

i=c(1,2,3,4,5,6,7,8,9,10,11,12) #identificando la estaci√≥n correspondiente a los m=12 per√≠odos de pron√≥sticos
```




```{r}
Stnuevo=deltas_i[i] #Asignando el valor de St a los periodos a pronosticar
Stnuevo=ts(Stnuevo,frequency=12,start=c(2019,1)) #convirtiendo en serie de tiempo al pron√≥stico de St
Stnuevo
```

```{r}
#Desestacionalizando o ajustando estacionalmente a la serie recortada, seg√∫n modelo aditivo
ytd=yt-St
```



```{r}
#LOESS cuadr√°tico (AICC) sobre serie desestacionalizada
mod3=loess.as(t,ytd,degree=2,criterion="aicc",family="gaussian",plot=F)
summary(mod3)
alfa.optim2=mod3$pars$span #guardando el valor √≥ptimo del par√°metro alfa
```




## Ajuste modelo 4 con m√©todo Suavizamiento exponencial Holt-Winters aditivo

### Modelo de tendencia con cambio de nivel y pendiente, aditiva a factor estacional con efectos que evolucionan lentamente en el tiempo

```{r}
mod4=HoltWinters(yt,seasonal="additive") #Suavizamiento con valores Optimos en parametros ùú∂, ùú∑, ùú∏
mod4
```




$$\begin{array}{| c | c | c | c| c |}
\hline\\
\hline
alpha:\alpha &0.2279994\\
beta:\beta &0.010042\\
gamma:\gamma &0.397323\\
\hline\\\hline
a:\hat{\beta}_{0,216}&101.9644720\\
b:\hat{\beta}_{1,216}&0.2949128\\
s1: \hat{\delta}_{1,216}&-12.3938476\\
s2: \hat{\delta}_{2,216}&-2.0117762\\
s3: \hat{\delta}_{3,216}& 3.6989236\\
s4: \hat{\delta}_{4,216}& 0.1017724\\
s5: \hat{\delta}_{5,216}& 6.8427850\\
s6: \hat{\delta}_{6,216}& 4.2348284\\
s7: \hat{\delta}_{7,216}& 2.7412904\\
s8: \hat{\delta}_{8,216}& 6.6698440\\
s9: \hat{\delta}_{9,216}&10.1574426\\
s10: \hat{\delta}_{10,216}&6.3504048\\
s11: \hat{\delta}_{11,216}&4.5463245\\
s12: \hat{\delta}_{12,216}&-9.2424032\\
\hline
\end{array}$$

# Ecuaciones ajustadas en modelos globales. Ecuaciones de suavizamiento Holt-Winters. Ajuste componente estacional por filtro de descomposici√≥n



$$\begin{array}{| c | c | c | c| c |}
\hline
Modelo & Ecuaci√≥n \\
\hline
1 & \hat{Y}_t \approx 35.8242551 + 0.1319807 t + 0.0007051 t^2	- 3.1817818 I_{1,t} + 5.3069465 I_{2,t} + 12.0220423 I_{3,t}+ 7.2690612 I_{4,t}+\\
& 12.1146698 I_{5,t}+ 9.8255350 I_{6,t}+ 8.4294343 I_{7,t} + 9.0930346 I_{8,t}+ 12.5163357 I_{9,t}+ 10.5493377 I_{10,t}+ 8.9475962 I_{11,t}\\
\hline
2 & \hat{Y}_t \approx 35.1122117 + 0.1689800 t + 0.0002800 t^2	+ 0.0000013 t^3 - 3.1146344 I_{1,t} + 5.3679308 
I_{2,t}+ 12.0768988 I_{3,t}+ \\
& 7.3178173 I_{4,t}+ 12.1573451 I_{5,t}+ 9.8621412 I_{6,t}+ 8.4599754 I_{7,t} +  9.1175066 I_{8,t}+ 12.5347270 I_{9,t}+ 10.5616286 I_{10,t}+ 8.9537593 I_{11,t}\\
\hline
3 & \hat{S}_t = \sum_{i=1}^{11}{\hat{\delta_i}I_{i,t}} =  -10.8780433 I_{1,t} - 2.3143178 I_{2,t} + 4.3650940 I_{3,t} - 0.5319649 I_{4,t}
 +4.3979371\\ 
& I_{5,t}+ 2.0783292 I_{6,t}+ 0.7969567 I_{7,t} + 1.2373979 I_{8,t}+ 4.6148489 I_{9,t}+ 2.5229371 I_{10,t}+ 1.0633783 I_{11,t}- 7.3525531 I_{12,t}\\
\hline
4 & \beta_{0,t} = 0.2279994(Y_t - \hat{S}_{t-12}) +  0.7720006(\hat{\beta}_{0,t-1} + \hat{\beta}_{1,t-1})\\
& \hat{\beta}_{1,t} = 0.010042(\hat{\beta}_{0,t} - \hat{\beta}_{0,t-1}) + 0.989958\hat{\beta}_{1,t-1}\\
&  \hat{S}_t = 0.397323(Y_t-\hat{\beta}_{0,t}) + 0.602677\hat{S}_{t-12}\\
& \hat{Y}_t = (\beta_{0,t-1} + \hat{\beta}_{1,t-1}) + \hat{S}_{t-12}\\
\hline
\end{array}$$




# Valores ajustados de los modelos 


Modelo 1

```{r}
mod1_ajust <- ts(fitted(mod1), start  = c(2001,1), frequency = 12)
```


```{r}
plot(Datos20)
lines(mod1_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste del modelo1"), lty=1, col=c(1,2))

```

Modelo 2

```{r}
mod2_ajust <- ts(fitted(mod2), start  = c(2001,1), frequency = 12)
```


```{r}
plot(Datos20)
lines(mod2_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste del modelo2"), lty=1, col=c(1,2))

```

modelo 3

```{r}
mod3_Tt <- ts(fitted(mod3), start  = c(2001,1), frequency = 12)
mod3_ajust <- mod3_Tt + St # Ajuste D&LC(AICC)
```


```{r}
plot(Datos20)
lines(mod3_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste D&LC(AICC)"), lty=1, col=c(1,2))

```




Modelo 4

```{r}
mod4_ajust <- fitted(mod4)[,1]
plot(Datos20)
lines(mod4_ajust, col=2, lwd=2)
legend("topleft", legend=c("Original","Ajuste H-W"), col=c(1,2), lty=1)
```

# Calculo del AIC y BIC

```{r}
#Creando funci?n usuario crit.inf.resid() para calcular C^*_n(p)
crit.inf.resid <- function(residuales,n.par,AIC="TRUE"){
if(AIC=="TRUE"){
#Calcula AIC
CI=log(mean(residuales^2))+2*n.par/length(residuales)
}
if(AIC=="FALSE"){
#Calcula BIC
CI=log(mean(residuales^2))+n.par*log(length(residuales))/length(residuales)
}
CI
}  
```

modelo 1
```{r}
resmod1.orig <- residuals(mod1) #seudo-residuos en la escala original. Usados solo para calcular AIC y BIC

npar1 <- length(coef(mod1)[coef(mod1)!=0]) #numero parametros modelo 1

AIC1 <- exp(crit.inf.resid(resmod1.orig,n.par=npar1))
BIC1 <- exp(crit.inf.resid(resmod1.orig ,n.par=npar1, AIC="FALSE"))
```

modelo 2
```{r}
resmod2.orig <- residuals(mod2) #seudo-residuos en la escala original. Usados s?lo para calcular AIC y BIC

npar2 <- length(coef(mod2)[coef(mod2)!=0]) #n?mero par?metros modelo 1

AIC2 <- exp(crit.inf.resid(resmod1.orig,n.par=npar2))
BIC2 <- exp(crit.inf.resid(resmod1.orig ,n.par=npar2, AIC="FALSE"))
```

modelo 3
```{r}
et3 <- yt - mod3_ajust

p3 <- round(mod3$enp)+s-1
AIC3 <- exp(crit.inf.resid(residuales=et3,n.par=p3))
BIC3 <- exp(crit.inf.resid(residuales=et3,n.par=p3,AIC="FALSE"))
```

modelo 4
```{r}
p4 <- 2+s-1 #Aprox. del n?mero de par?metros del suavizamiento
AIC4 <- exp(crit.inf.resid(residuales=residuals(mod4),n.par=p4))
BIC4 <- exp(crit.inf.resid(residuales=residuals(mod4),n.par=p4,AIC="FALSE"))
```

```{r}
library(kableExtra)
```

```{r}
Modelo <- c(1,2,3,4)
p <- c(npar1, npar2, p3, p4)
AIC <- c(AIC1, AIC2, AIC3, AIC4)
BIC <- c(BIC1, BIC2, BIC3, BIC4)
Criterios_inf <- data.frame(Modelo, p, AIC, BIC) 
```


$$\begin{array}{| c | c | c |}
\hline
Modelo&p&AIC&BIC\\
\hline
1&14&16.85948&20.98234\\
2&15&17.01631&21.51105\\
3&24&11.18417&16.27338\\
4&13&16.87146&20.84412\\
\hline
\end{array}$$

Con relaci√≥n a la calidad de ajuste, vemos un ajuste muy similar entre los modelos, todos consiguen seguir muy bien los patrones de tendencia, estacionalidad y al parecer tambi√©n los ciclos. Por otro lado, los valores de AIC y BIC tambi√©n son similares aunque num√©ricamente resulta menor el del modelo 3, tanto AIC y BIC coinciden en el mismo modelo. El modelo de regresi√≥n cubico con indicadoras tiene el mayor en AIC y BIC (aunque como ya se indic√≥, el grado del polinomio no es significativo).

#############################################################################

# Preguntas orientadas para los analisis
## hacer tablas de los summary

..............................................................................
 **En los modelos globales ¬øSon significativos el polinomio considerado y la componente estacional con la representaci√≥n que fue usada?**
 
 

Modelo 1

Debido a que el valor ajustado para el coeficiente correspondiente al grado 2 del polinomio tiene un p-valor muy peque√±o(menor a 0.05), se dice que es significativo y por lo tanto la estructura del polinomio cuadr√°tico es significativa.
Por otro lado, ya que al menos uno de los coeficientes estimados asociados a las variables indicadoras, son significativos(p-valor menor a 0.05), en este caso todos, se concluye que la componente estacional es significativa.

Modelo 2

Debido a que el valor ajustado para el coeficiente correspondiente al grado 3 del polinomio tiene un p-valor grande(mayor a 0.05), se dice que no es significativo y por lo tanto la estructura del polinomio c√∫bico no es significativa.
Por otro lado, ya que al menos uno de los coeficientes estimados asociados a las variables indicadoras, son significativos(p-valor menor a 0.05), en este caso todos, se concluye que la componente estacional es significativa.


Conclusi√≥n:

Desarrollando los tests enunciados en la Tabla de hipotesis, con base en resultados, se concluye que el modelo1 global es significativo el respectivo polinomio propuesto (aunque esto no implica que el modelo es correcto), en cambio el modelo2 no es significativo respecto al polinomio propuesto. Para la componente estacional, a un nivel de significancia de 0.05, en ambos modelos se concluye que todos los $\delta_i$ son estad√≠sticamente significativos,  incluso siendo solo uno de ellos significativo es suficiente para afirmar que la componente estacional modelada globalmente como un factor, es estad√≠sticamente significativa.
..............................................................................

**En los modelos globales ¬øCu√°l es la interpretaci√≥n de las estimaciones de los par√°metros estacionales?**

Ya que la serie es aditiva, los $\delta_i$ es la diferencia entre la media de la serie en el mes i del a√±o menos la media en el periodo de referencia, es decir, diciembre.

Interpretaci√≥n del $\delta_1=-3.18178$ en el modelo 1:

* El modelo 1 estima que en promedio del indice de producci√≥n nominal en el mes de enero disminuyo en 3.18178 unidades en comparaci√≥n con el del mes de diciembre en cada a√±o.


$$\begin{array}{| c | c | c |}
\hline
\delta~i&Modelo~1&Modelo~2\\
\hline
\delta_1&-3.181782&-3.114634\\
\delta_2&5.306946&5.367931\\
\delta_3&12.022042&12.076899\\
\delta_4&7.269061&7.317817\\
\delta_5&12.114670&12.157345\\
\delta_6&9.825535&9.862141\\
\delta_7&8.429434&8.459975\\
\delta_8&9.093035&9.117507\\
\delta_9&12.516336&12.534727\\
\delta_{10}&10.549338&10.561629\\
\delta_{11}&8.947596&8.953759\\
\hline
\end{array}$$



**¬ødifieren mucho estas estimaciones entre los modelos globales?**

* Las estimaciones de los par√°metro asociados a la variables indicadora que modelan la estacionalidad difieren minimamente en los modelos globales.


**Adem√°s, si se modelo con variables indicadoras, grafique en un mismo plano y en la escala original de la serie, el patr√≥n estacional estimado ¬øEstas estimaciones aproximan apropiadamente el patr√≥n estacional? Esta gr√°fica puede realizarse de la siguiente manera: Suponga que los modelos son ajustados en R bajo los objetos de nombre mod1 y mod2 respectivamente. Sean p1 y p2 los ordenes de los respectivos polinomios, nparmod1 y nparmod2 el n√∫mero de par√°metros, de cada modelo, respectivamente. En el caso aditivo, proceda as√≠:**



```{r}
p1 <- 2 # grado del polinomio modelo 1
p2 <- 3 # grado del polinomio modelo 2


efectosestac1 <- ts(c(coef(mod1)[(p1+2):npar1],0),freq=1,start=1)
efectosestac2 <- ts(c(coef(mod2)[(p2+2):npar2],0),freq=1,start=1)
plot(efectosestac1,lwd=4,ylab="",xlab="Periodo del a√±o", col="blue")
lines(efectosestac2,lty=2,col="cyan4",lwd=4)
grid()
legend("topleft",legend=c("Modelo 1","Modelo 2"),col=c("blue", "cyan4"),lty=1:2,lwd=2)
```


Vemos que el mod1 y el mod2 estiman la misma forma para $S_t$ adem√°s de que sus valores son muy similares para los efectos estacionales (no son iguales pero tinen diferencias muy peque√±as en las estimaciones de los $\delta_i$)

* Mediante el gr√°fico se puede notar que las estimaci√≥n del $\delta_1$ que es el del mes de enero es la √∫nica con valor negativo, es decir es el √∫nico mes donde la producci√≥n nominal tuvo una disminuci√≥n respecto al mes de diciembre que es el de referencia, por lo tanto para el resto de meses de febrero a noviembre tuvo un aumento en comparaci√≥n con el mes de diciembre (Este es un comportamiento dentro de cada a√±o).

* Se puede visualizar mediante la gr√°fica que la estimaci√≥n del $\delta$ para el mes 12 es decir de diciembre toma el valor de cero, debido a que es el mes de referencia.

.............................................................................



 **Compare gr√°ficamente la forma de la estimaci√≥n de la componente estacional entre los dos modelos locales(en Holt-Winters se toma el  √∫ltimo valor suavizado para cada uno de los 12 efectos estacionales) ¬ødifieren mucho? Adem√°s, si en los modelos globales se usaron indicadoras, compare la forma del patr√≥n estacional estimado por estos vs. los locales ¬øqu√© se interpreta a partir de la similaridad o diferencia entre estas estimaciones?**
 
 
```{r}
#extracci√≥n estimaciones en t=216 de efectos estacionales segun Holt-Winters.

deltasiHW=ts(mod4$coef[c(3:14)],freq=1,start=1)#Estimaciones de los efectos estacionales segun filtro de descomposici√≥on

deltasDescomp=ts(deltas_i,freq=1,start=1)
deltasilocales=data.frame(rbind(deltasiHW,deltasDescomp),row.names=c("HW","Descomp&loess"))
names(deltasilocales)=c(1:12)#Gr√°fico de los efectos estacionales estimados


plot(deltasiHW,lwd=4,ylim=c(min(deltasiHW,deltasDescomp),max(deltasiHW,deltasDescomp)+0.05),ylab="",xlab="Mes del a√±o")
lines(deltasDescomp,lty=2,lwd=4,col=2)
grid()
legend("topleft",legend=c("Efectos estacionales H-W en t=216","Efectos estacionales Filtro de descomposici√≥n"),col=1:2,lty=1:2,lwd=3, cex=0.7)
```

* En esta figura vemos que la forma del patr√≥n estacional que estima al final Holt-Winters y el que estima globalmente el filtro de la descomposici√≥n, es muy similar aunque se observan algunas diferencias que destacan para los meses de
mayo a noviembre, periodos del a√±o en los que Holt-Winters termina con estimaciones mayores a las del filtro. Podemos decir que dado lo anterior, la forma del patr√≥n estacional es m√°s o menos estable y que en esta componente
las proyecciones en los pron√≥sticos ex‚Äìpost del filtro y de Holt-Winters, no distan mucho.



```{r}
plot(efectosestac1,lwd=3, col="blue", xlab="Periodo del a√±o", ylim =c(-10,23))
lines(efectosestac2,lty=2,col="cyan4",lwd=4)
lines(deltasiHW,lwd=3, col=3)
lines(deltasDescomp,lty=2,lwd=4,col="purple")
grid()
legend("topleft",legend=c("Polinomial cuadr√°tico","Polinomial c√∫bico", "SEHW","DLC"),col=c("blue", "cyan4", 3, "purple"),lwd=3, cex=0.8)
```


* Vemos que los modelos globales respecto a los locales estiman la misma forma de $S_t$ pero con valores diferentes de los efectos estacionales al no coindir los $\delta_i$

..............................................................................


**Con relaci√≥n al ajuste loess de la serie desestacionalizada ¬øQu√© se concluye de su gr√°fica y del n√∫mero de par√°metros equivalentes loess?**
 
# GR√ÅFICOS DE LA SERIE DESESTACIONALIZADA Y SUS AJUSTES LOESS

```{r}
plot(ytd, ylab="")
lines(mod3_Tt, col=2, lwd = 2)
grid()
legend("topleft", legend=c("Serie ajustada estacionalmente", "Tendencia LOESS cuadr√°tico (AICC)"), col=c(1,2), lty=1)
``` 


Se observa que los valores ajustados se acercan a los valores que toma la serie; la componente ciclica que toma la serie esta presente ya que se puede observar que la tendencia no es una curva completamente suave. 

Finalmente el ajuste que hace LOESS al final de la serie es creciente, aunque el valor real muestra una tendencia decreciente

Para un ajuste global polinomial alcanzando el mismo ajuste que LOESS, el modelo global deberia ser un polinomial con aproximadamente 13 par√°metros.

.............................................................................


**¬øQu√© se concluye sobre la calidad del ajuste de los modelos globales vs. locales? tambi√©n determine entre los modelos globales cu√°l modelo recomendar√≠a inicialmente como mejor modelo global para ajustar la serie. Tenga en cuenta no s√≥lo los valores de los criterios de informaci√≥n, sino tambi√©n los resultados gr√°ficos.**

(En las diapositivas colocar nuevamente las graficas de ajuste y la tabla de los criterios de informaci√≥n)


```{r}
par(mfrow=c(2,2))
plot(Datos20)
lines(mod1_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste del modelo1"), lty=1, col=c(1,2), cex=0.5)

plot(Datos20)
lines(mod2_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste del modelo2"), lty=1, col=c(1,2), cex=0.5)

plot(Datos20)
lines(mod3_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste D&LC(AICC)"), lty=1, col=c(1,2), cex=0.5)

plot(Datos20)
lines(mod4_ajust, col=2, lwd=2)
legend("topleft", legend=c("Original","Ajuste H-W"), col=c(1,2), lty=1, cex=0.5)
```



* En general mediante los gr√°ficos tiene un mejor ajuste los modelos locales que los globales


*  Entre los modelos globales se recomienda el modelo cuadr√°tico con indicadoras ya que con un grado menos del polinomio ajusta igual de bien que el c√∫bico, por tanto se prefiere por ser un modelo m√°s simple (parsimonioso) adem√°s que en los ajustes se noto que el grado 3 del polinomio del segundo modelo no es significativo.

* Mediante los criterios del AIC y BIC se prefiere al modelo 3 (DLC) dado que es el de menor valor

* Mediante el AIC y BIC de los modelos globales se escoge modelo2 (cuadr√°tico) dado que toma los menores valores en estos criterios de informaci√≥n.

..............................................................................


# 4. An√°lisis de residuales y validaci√≥n de supuestos: Para todos los modelos ajustados, globales y locales, realice el an√°lisis comparativo de residuales.


Gr√°fico de los residuales en el tiempo

```{r}
par(mfrow=c(2,2))

# Residuales vs tiempo mod1
plot.ts(residuals(mod1))
abline(h=c(-2*summary(mod1)$sigma, 0, 2*summary(mod1)$sigma), col=2)
legend("topleft", legend=c("Modelo1"), lty=1, col = 1, lwd=2)


# Residuales vs tiempo mod2
plot.ts(residuals(mod2))
abline(h=c(-2*summary(mod2)$sigma, 0, 2*summary(mod2)$sigma), col=2)
legend("topleft", legend=c("Modelo2"), lty=1, col = 1, lwd=2)


# Residuales vs tiempo mod3
df=n-(round(mod3$enp)+s-1) #Grados de libertad aproximados del ajuste total
MSE3=sum(et3^2)/df #MSE aproximado del ajuste total del modelo 3
plot(et3,ylim=c(min(-2*sqrt(MSE3),et3),max(2*sqrt(MSE3),et3)))
abline(h=c(-2*sqrt(MSE3),0,2*sqrt(MSE3)),col=2)
legend("topleft", legend=c("Modelo3"), lty=1, col = 1, lwd=2)


# Residuales vs tiempo mod4

et4=residuals(mod4)
df4=n-2*s-((s-1)+2)
MSE4=mod4$SSE/df4 #MSE aproximado del ajuste total del Suavizamiento

plot(et4,ylim=c(min(-2*sqrt(MSE4),et4),max(2*sqrt(MSE4),et4)))
abline(h=c(-2*sqrt(MSE4),0,2*sqrt(MSE4)),col=2)
legend("topleft", legend=c("Modelo4"), lty=1, col = 1, lwd=2)



```

```{r}

par(mfrow=c(2,2))
# Residuales vs valores ajustados mod1

plot(fitted(mod1), residuals(mod1))
abline(h=c(-2*summary(mod1)$sigma, 0, 2*summary(mod1)$sigma), col=2)
legend("topleft", legend=c("Modelo1"), lty=1, col = 1, lwd=2,cex = 0.8)


# Residuales vs valores ajustados mod2

plot(fitted(mod2), residuals(mod2))
abline(h=c(-2*summary(mod2)$sigma, 0, 2*summary(mod2)$sigma), col=2)
legend("topleft", legend=c("Modelo2"), lty=1, col = 1, lwd=2,cex = 0.8)

# Residuales vs valores ajustados mod3
plot(as.numeric(mod3_ajust),et3,ylim=c(min(-2*sqrt(MSE3),et3),max(2*sqrt(MSE3),et3)))
abline(h=c(-2*sqrt(MSE3),0,2*sqrt(MSE3)),col=2)
legend("topleft", legend=c("Modelo3"), lty=1, col = 1, lwd=2,cex = 0.8)

# Residuales vs valores ajustados mod4

plot(as.numeric(mod4_ajust),et4,ylim=c(min(-2*sqrt(MSE4),et4),max(2*sqrt(MSE4),et4)))
abline(h=c(-2*sqrt(MSE4),0,2*sqrt(MSE4)),col=2)
legend("topleft", legend=c("Modelo4"), lty=1, col = 1, lwd=2,cex = 0.8)
```

**Sobre el supuesto de media cero para los errores de ajuste ¬øqu√© se concluye en los cuatro modelos?**

En las figuras presentadas en las gr√°ficas de residuos vs. tiempo y vs. valores ajustados, no se observa evidencia contra el supuesto de que los errores tienen media cero (a pesar de la variaci√≥n c√≠clica alrededor de cero, que se observa en las series de tiempo de los residuos de los modelos globales), pues en todos los casos los residuos parecen bien centrados en cero.


* ¬øEs v√°lido el supuesto de varianza constante en los 4 modelos?

Se observa una distribuci√≥n relativamente homog√©nea de los residuos alrededor de cero, es decir, no hay evidencias contrariando el supuesto de varianza constante para los errores de ajuste. 


* ¬øHay patrones en los residuos que indiquen carencia de ajuste de los modelos en la tendencia y/o la estacionalidad?

No hay evidencia de carencia de ajuste en las componentes estructurales (o sea en tendencia y estacionalidad), pues en los residuos vs. valores ajustados no se observan patrones claros con forma de U o de W que indiquen mal ajuste de la tendencia, ni patrones peri√≥dicos en las gr√°ficas de las series de tiempo de residuos de ajuste que indiquen mal ajuste de la estacionalidad.


* ¬øHay ciclos presentes en los residuales? ¬øqu√© se deriva de estos patrones?

En las series de tiempo de los residuos de los modelos globales hay evidencia de ciclos no explicados (los cuales se dan centrados en cero), esto implica que los errores en los modelos globales, separados un periodo en el tiempo, est√°n positivamente correlacionados, es decir, $Corr(E_t,E_{t+1}) > 0$, por lo cual ya no es v√°lido el supuesto de independencia.

Por el contrario, en las series de tiempo de los residuos de los dos modelos locales no son observables a simple vista patrones c√≠clicos, aunque esto no es una garant√≠a suficiente para afirmar la validez de la independencia entre los errores de ajuste de estos dos modelos, es un punto su favor.


* ¬øQu√© hacen mejor los m√©todos locales vs. los globales

En general todos los modelos parecen no tener evidencia en contra de los supuestos de media cero y varianza constante, por lo que esto es positivo pero los m√©todos locales logran seguir ciclos, por eso son mejores que los modelos globales.


* ¬øCu√°l es el mejor modelo de los cuatro, de acuerdo al an√°lisis de los residuales?

Con todo lo antes dicho, de los 4 modelos, se considera que los modelos de ajuste local son mejores, ya que en ellos no hay patrones c√≠clicos y por tanto dan indicios de no incumplir el supuesto de independencia.

* Si es necesario elegir entre los locales, hasta el momento se prefiere el modelo 3 ya que le fue bien los supuestos del modelo y fue el mejor en los ajustes, solo queda mirar en los pronosticos para garantizar de que es el mejor.

...................................................................................


# 5. Pron√≥sticos para la validaci√≥n cruzada: Para todos los modelos de ajuste global y local presentados, presente los resultados y an√°lisis de pron√≥sticos puntuales y por intervalos.



$$\begin{array}{| c | c | c | c| c |}
\hline
Modelo & Ecuaciones~de~Pron√≥sticos \\
\hline
1 & \hat{Y}_{216}(L) \approx 35.8242551 + 0.1319807 (216+L) + 0.0007051 (216+L)^2	- 3.1817818 I_{1,216+L} +\\
& 5.3069465 I_{2,216+L} + 12.0220423 I_{3,216+L}+ 7.2690612 I_{4,216+L}+ 12.1146698 I_{5,216+L}+ 9.8255350 I_{6,216+L}+\\
& 8.4294343 I_{7,216+L} + 9.0930346 I_{8,216+L}+ 12.5163357 I_{9,216+L}+ 10.5493377 I_{10,216+L}+ 8.9475962 I_{11,216+L}\\
\hline
2 & \hat{Y}_{216}(L) \approx 35.1122117 + 0.1689800 (216+L) + 0.0002800 (216+L)^2	+ 0.0000013 (216+L)^3 - 3.1146344 I_{1,216+L} +\\
& 5.3679308I_{2,216+L}+ 12.0768988 I_{3,216+L}+ 7.3178173 I_{4,216+L}+ 12.1573451 I_{5,216+L}+ 9.8621412 I_{6,216+L}+\\
& 8.4599754 I_{7,216+L} +  9.1175066 I_{8,216+L}+ 12.5347270 I_{9,216+L}+ 10.5616286 I_{10,216+L}+ 8.9537593 I_{11,216+L}\\
\hline
3 & \hat{Y}_{216}(L) = \left(\hat{\beta}_{0,216} + \hat{\beta}_{1,216}(216+L) + \hat{\beta}_{2,216}(216+L)^2\right)+ \left(-10.8780433 I_{1,216+L} - 2.3143178 I_{2,216+L}\\ + 4.3650940 I_{3,216+L}
- 0.5319649 I_{4,216+L}+ 4.3979371 I_{5,216+L}+ 2.0783292 I_{6,216+L}+ 0.7969567 I_{7,216+L}\\ + 1.2373979 I_{8,216+L}+ 4.6148489 I_{9,216+L}+ 2.5229371 I_{10,216+L}+ 1.0633783 I_{11,216+L} - 7.3525531 I_{12,216+L}\right)\\
\hline
4 & \hat{Y}_{216}(L) = (101.9644720 + 0.2949128\times L)+(-12.3938476I_{1,216+L} - 2.0117762I_{2,216+L} + 3.6989236I_{3,216+L} +\\ & 0.1017724I_{4,216+L} + 6.8427850 I_{5,216+L}+ 4.2348284 I_{6,216+L}+ 2.7412904 I_{7,216+L} + 6.6698440 I_{8,216+L}+\\
& 10.1574426 I_{9,216+L} + 6.3504048 I_{10,216+L} + 4.5463245 I_{11,216+L} - 9.2424032 I_{12,216+L})\\
\hline
\end{array}$$

#### Hacer tabla de ecuaciones de pron√≥stico
#### Tabla con los pron√≥sticos

Valores reales 
```{r}
ytnuevo
```

$$\begin{array}{| c | c | c | c| c |}
\hline
Ene&Feb&Mar&Abr&May&Jun&Jul&Ago&Sep&Oct&Nov&Dic\\
\hline
87.3&102.1&108.5&104.0&112.0&103.3&110.3&109.4&112.1&114.7&109.2&103.3\\
\hline
\end{array}$$



```{r}
kable(data.frame(ytnuevo))
```


Modelo 1

```{r}
ytpron1 <- predict(mod1, newdata=data.frame(t=tnuevo, I1=I1n, I2=I2n, I3=I3n, I4=I4n, I5=I5n, I6=I6n, I7=I7n, I8=I8n, I9=I9n, I10=I10n, I11=I11n), interval="prediction")
ytpron1 <- ts(ytpron1,freq=12,start=c(2019,1))
ytpron1
```


$$\begin{array}{| c | c | c | c| c |}
\hline
Periodo&L&Pron√≥sticos&Lim.Inf&Lim.Sup\\
\hline
Ene~2019&1&94.4852&86.27520&102.6952\\
Feb~2019&2&103.4126&95.19741&111.6279\\
Mar~2019&3&110.5678&102.34725&118.7884\\
Abr~2019&4&106.2564&98.03028&114.4825\\
May~2019&5&111.5449&103.31316&119.7767\\
Jun~2019&6&109.7001&101.46257&117.9377\\
Jul~2019&7&108.7498&100.50627&116.9933\\
Ago~2019&8&109.8606&101.61094&118.1102\\
Sep~2019&9&113.7324&105.47658&121.9883\\
Oct~2019&10&112.2154&103.95319&120.4777\\
Nov~2019&11&111.0651&102.79632&119.3338\\
Dic~2019&12&102.5703&94.29486&110.8457\\
\hline
\end{array}$$



Modelo 2

```{r}
ytpron2 <- predict(mod2, newdata=data.frame(t=tnuevo, I1=I1n, I2=I2n, I3=I3n, I4=I4n, I5=I5n, I6=I6n, I7=I7n, I8=I8n, I9=I9n, I10=I10n, I11=I11n), interval="prediction")
ytpron2 <- ts(ytpron2,freq=12,start=c(2019,1))
ytpron2
```


$$\begin{array}{| c | c | c | c| c |}
\hline
Periodo&L&Pron√≥sticos&Lim.Inf&Lim.Sup\\
\hline
Ene~2019&1&95.19725&86.84148&103.5530\\
Feb~2019&2&104.15594&95.78241&112.5295\\
Mar~2019&3&111.34331&102.95097&119.7356\\
Abr~2019&4&107.06490&98.65269&115.4771\\
May~2019&5&112.38738&103.95418&120.8206\\
Jun~2019&6&110.57743&102.12208&119.0328\\
Jul~2019&7&109.66281&101.18411&118.1415\\
Ago~2019&8&110.81020&102.30691&119.3135\\
Sep~2019&9&114.71959&106.19043&123.2487\\
Oct~2019&10&113.24098&104.68463&121.7973\\
Nov~2019&11&112.12994&103.54501&120.7149\\
Dic~2019&12&103.67534&95.06044&112.2903\\
\hline
\end{array}$$



Modelo 3

```{r}
#Pron√≥sticos de la tendencia por loess cuadr√°tico √≥ptimo (AICC)
Ttnuevo3 <- predict(loess(ytd~t,span=alfa.optim2,degree=2,control=loess.control(surface="direct")),
data.frame(t=tnuevo),se=FALSE)
Ttnuevo3 <- ts(Ttnuevo3,freq=12,start=c(2019,1)) #convirtiendo en serie de tiempo al pron√≥stico de Tt, modelo 3
ytpron3 <- Ttnuevo3 + Stnuevo #Pron√≥stico puntual Modelo 2
#Tabla con pron√≥sticos de las componentes y de la serie, Modelo 2
tablapron3 <- cbind(Pron_Tt=Ttnuevo3,Pron_St=Stnuevo,Pron_serie=ytpron3)
tablapron3
```

$$\begin{array}{| c | c | c | c| c |}
\hline
Fecha&L&\hat{T}_{216}(L)&\hat{S}_{216}(L)&\hat{Y}_{216}(L)=\hat{T}_{216}(L)+\hat{S}_{216}(L)\\
\hline
Ene~2019&1&103.9982&-10.8780433&93.12013\\
Feb~2019&2&104.6239&-2.3143178&102.30959\\
Mar~2019&3&105.2877&4.3650940&109.65277\\
Abr~2019&4&105.9900&-0.5319649&105.45802\\
May~2019&5&106.7313&4.3979371&111.12925\\
Jun~2019&6&107.5121&2.0783292&109.59040\\
Jul~2019&7&108.3326&0.7969567&109.12959\\
Ago~2019&8&109.1933&1.2373979&110.43074\\
Sep~2019&9&110.0945&4.6148489&114.70934\\
Oct~2019&10&111.0364&2.5229371&113.55930\\
Nov~2019&11&112.0192&1.0633783&113.08259\\
Dic~2019&12&113.0433&-7.3525531&105.69070\\
\hline
\end{array}$$



Modelo 4

```{r}
pronos4 <- predict(mod4, n.ahead=12,prediction=T,level=0.95)
ytpron4 <- pronos4[,1] #s√≥lo los pron√≥sticos puntuales del suavizamiento
```

$$\begin{array}{| c | c | c | c| c |}
\hline
Periodo&L&Pron√≥sticos&Lim.Sup&Lim.Inf\\
\hline
Ene~2019&1&89.86554&97.40692&82.32415\\
Feb~2019&2&100.54252&108.28129&92.80375\\
Mar~2019&3&106.54813&114.48318&98.61309\\
Abr~2019&4&103.24590&111.37622&95.11557\\
May~2019&5&110.28182&118.60654&101.95710\\
Jun~2019&6&107.96878&116.48710&99.45046\\
Jul~2019&7&106.77015&115.48136&98.05894\\
Ago~2019&8&110.99362&119.89709&102.09014\\
Sep~2019&9&114.77613&123.87132&105.68094\\
Oct~2019&10&111.26400&120.55041&101.97759\\
Nov~2019&11&109.75484&119.23204&100.27763\\
Dic~2019&12&96.26102&105.92865&86.59339\\
\hline
\end{array}$$




Preguntas orientadas

**¬øCu√°l es la interpretaci√≥n de los pron√≥sticos puntuales y sus I.P? Ejemplificar con una fecha y comparar entre modelos.**

* Los pron√≥sticos puntuales, indican el valor que cada modelo ajustado con los primeros n = 216 datos, predice que ser√° observado para la serie en cada periodo de los pron√≥sticos ex-posts.

* Los pron√≥sticos por intervalos, indican que el valor real estar√° en el intervalo de cada uno de los modelos con una confianza del 95%.

La producci√≥n nominal de la clase industrial otros productos qu√≠micos para el mes de Junio de 2019, comparado con los meses del a√±o 2018 es de:

+ En el __modelo global cuadr√°tico__ : 109.59040 % es decir, durante este periodo aument√≥ un 9.59%. Adem√°s, con un 95% de confianza el valor real del √≠ndice se encuentra entre 101.46257 y 117.9377. 

+ En el __modelo global c√∫bico__ : 110.57743% es decir, durante este periodo aument√≥ aproximadamente un 10.57%. Adem√°s, con un 95% de confianza el valor real del √≠ndice se encuentra entre 102.12208 y 119.0328 .

+ En el __modelo local con Descomposici√≥n aditiva & Loess cuadr√°tico (DLC)__ : 109.12959 es decir, durante este periodo aument√≥ aproximadamente un 9.13%.

+ En el __modelo local aditivo con SEHW__: 107.96878% es decir, durante este periodo aument√≥ aproximadamente un 7.9%. Adem√°s, con un 95% de confianza el valor real del √≠ndice se encuentra entre 99.45046 y 116.48710  



**¬øCu√°l es la interpretaci√≥n de las medidas MAE, MAPE y RMSE? ¬øseg√∫n estas medidas cu√°l modelo pronostica mejor?**


# Medidas en todos los modelos

```{r}
a <-accuracy(ytpron1,ytnuevo) #Modelo 1
b <- accuracy(ytpron2,ytnuevo) #Modelo 2
c <- accuracy(ytpron3,ytnuevo) #Modelo 3
d <- accuracy(ytpron4,ytnuevo) #Modelo 4

rbind(a,b,c,d)
```

Interpretaciones:

  - Modelo 1:
  
  En promedio en cada pronostico se estima un error de +- 3.153708 puntos del indice de producci√≥n nominal seg√∫n el RMSE y de +- 2.366654 puntos del indice de producci√≥ nominal seg√∫n MAE, mientras que MAPE estima que en promedio cada pronostico se comete un error de +-2.338% con relaci√≥n al valor real del indice de producci√≥n nominal, todo esto en el modelo de regresi√≥n cuadr√°tico con variables indicadores
  
     
  - Modelo 2:
  
  En promedio en cada pronostico se estima un error de +- 3.620468 puntos del indice de producci√≥n nominal seg√∫n el RMSE y de +- 2.746457 puntos del indice de producci√≥ nominal seg√∫n MAE, mientras que MAPE estima que en promedio cada pronostico se comete un error de +- 2.71% con relaci√≥n al valor real del indice de producci√≥n nominal, todo esto en el modelo de regresi√≥n c√∫bico con variables indicadores.
  
  
   - Modelo 3:
  
  En promedio en cada pronostico se estima un error de +- 3.014298 puntos del indice de producci√≥n nominal seg√∫n el RMSE y de +- 2.33551 puntos del indice de producci√≥ nominal seg√∫n MAE, mientras que MAPE estima que en promedio cada pronostico se comete un error de +- 2.28% con relaci√≥n al valor real del indice de producci√≥n nominal, todo esto en el modelo de Filtro de decomposici√≥n combinado Loess cuadr√°tico.
  
  
   - Modelo 4:
  

  En promedio en cada pronostico se estima un error de +- 3.187973 puntos del indice de producci√≥n nominal seg√∫n el RMSE y de +- 2.670446 puntos del indice de producci√≥ nominal seg√∫n MAE, mientras que MAPE estima que en promedio cada pronostico se comete un error de +- 2.53% con relaci√≥n al valor real del indice de producci√≥n nominal, todo esto en el modelo de SEHW.
  
R/ Seg√∫n las medidas de pron√≥sticos el mejor modelo es el modelo 3(Usa filtro de descomposici√≥n con loess cuadr√°tico)
  
  
**Con base en la amplitud media y cobertura de los I.P ¬øqu√© se concluye?**


(... Tablas de amplitud y cobertura en los modelos ...)


```{r}
#Creando funci√≥n usuario amplitud() para calcular la amplitud promedio de los I.P en pron√≥sticos ex ‚Äì post
amplitud=function(LIP,LSP){
a=LSP-LIP
am=mean(a)
am
}
#Creando funci√≥n usuario cobertura() para calcular la cobertura de los I.P en pron√≥sticos ex ‚Äì post
cobertura=function(real,LIP,LSP){
I=ifelse(real>=LIP & real<=LSP,1,0)
p=mean(I)
p
}
```


Modelo 1:

```{r}
amplitud(LIP=ytpron1[,2],LSP=ytpron1[,3])
cobertura(real=ytnuevo,LIP=ytpron1[,2],LSP=ytpron1[,3])
```


Modelo 2:


```{r}
amplitud(LIP=ytpron2[,2],LSP=ytpron2[,3])
cobertura(real=ytnuevo,LIP=ytpron2[,2],LSP=ytpron2[,3])
```

Modelo 4:

```{r}
#Precisi√≥n pron√≥sticos por I.P Holt-Winters

amplitud(LIP=pronos4[,3],LSP=pronos4[,2])
cobertura(real=ytnuevo,LIP=pronos4[,3],LSP=pronos4[,2])
```

Seg√∫n este criterio todos los modelos que tienen intervalo de predicci√≥n tienen una cubertura del 100%, es decir todos los valores reales caen en el intervalo.

El modelo 1 es el de menor amplitud, por lo tanto seg√∫n este criterio seria el mejor modelo.




$$\begin{array}{| c | c | c | c| c |}
\hline
RMSE & MAE & MAPE & Amplitud & Cobertura()\\
3.153708&2.366654&2.338060&16.48278&100\\
3.620468&2.746457&2.711682&16.94829&100\\
3.014298&2.335510&2.283224&-&-\\
3.187973&2.670446&2.533667&17.22162&100\\
\hline
\end{array}$$



* ¬øQu√© se concluye de la figura comparativa de los pron√≥sticos puntuales?


```{r}
plot(ytnuevo,lwd=2, col=1, type="b", pch=1, xlab="Periodo del a√±o", ylab="")
lines(ytpron1[,1],lwd=2, col=2, type="b", pch=2)
lines(ytpron2[,1],lwd=2, col=3, type="b", pch=3)
lines(ytpron3,lwd=2,col=4, type="b", pch=4)
lines(ytpron4,lwd=2,col=5, type="b", pch=5)
grid()
legend("bottomright",legend=c("Real","Pronostico modelo1", "Pronostico modelo2", "Pronostico modelo3", "Pronostico modelo4"),col=1:5,lwd=2, pch=1:5, cex=0.8)
```

* En base a la gr√°fica de pronosticos se escoge como mejor modelo el modelo 3.


# 6. Conclusiones del trabajo: 

En esta secci√≥n debe presentar un resumen de los resultados encontrados en el respectivo trabajo, as√≠ como enunciar los problemas enfrentados en la modelaci√≥n, postular cu√°l ha sido el mejor modelo en ajuste y pron√≥stico entre los tratados y comentar acerca de lo que usted crea que logr√≥ este mejor modelo:

* ¬øCaptur√≥ la din√°mica de la serie?

* ¬øSu tendencia, estacionalidad y sus variaciones c√≠clicas son bien ajustadas?

* ¬øLos pron√≥sticos parecen realistas y confiables?

* ¬øQu√© otras alternativas podr√≠an haberse propuesto? (falta)

* ¬øCr√≠ticas al mejor modelo que encontr√≥ en el trabajo actual? 

* Exprese claramente qu√© recomienda para la serie en cuanto a ajustes globales o locales, seg√∫n lo realizado hasta el momento. (falta)



Conclusi√≥n:

Teniendo como primer criterio de selecci√≥n los resultados en el an√°lisis de residuales, en segundo lugar los resultados de pron√≥sticos y por √∫ltimo los de ajustes, se concluye que el mejor modelo por el momento, es el modelo 3, este no mostro evidencia en contra de los supuestos(aunque a√∫n no se ha probado el supuesto de independencia ni el de normalidad), adem√°s captur√≥ muy bien la dinamica de la serie, este tiene las mejores medidas de pronostico y ajuste, adem√°s de que sigue bien la tendencia, estacionalidad y variaciones ciclicas, aunque en algunos pronosticos no parece ser tan realista y confiable debido a que en la mayoria tiende a subestimar los valores y al final de los pronosticos es el modelo m√°s alejado del valor real, por tanto se cree que podria cometer errores en pronosticos ex-ante, por lo tanto puede haberse considerado modelos. 























