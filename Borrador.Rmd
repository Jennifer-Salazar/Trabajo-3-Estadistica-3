---
title: "Borrador"
author: "Jennifer Salazar"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Falta hacer esto

Defina la variable de la serie, su unidad de medida, su construcción e interpretacion de sus cifras, perıodos observados, frecuencia de observacion, total de observaciones y fuente de los datos.



# Librerias utiles

```{r}
library(forecast)
library(TSA)
library(fANCOVA)

```

```{r}
Datos20=read.table("anex-EMMET-dic2019-Fabricacion de otros productos quimicos (1).csv",header=T,sep=";",skip=14,dec=",",colClasses=c(rep("NULL",4),"numeric",rep("NULL",6)))
Datos20=ts(Datos20,freq=12,start=c(2001,1))
```



# Análisis descriptivo:

Se Consideran los datos sobre el índice de producción nominal de la clase otros productos quimicos sector de manufactura, de enero de 2001 a diciembre de 2019
(N=228), año base 2018. Ver Figura 1(a).


## Descomposición aditiva (tendencia)

```{r}
Tt=decompose(Datos20)$trend
```


```{r}
par(mfrow=c(1,2))
plot(Datos20, sub="(a)", lwd=1.5)
grid()
plot(Tt,ylim=c(min(Datos20),max(Datos20)), sub="(b)", lwd=1.5, ylab=expression(T[t]))
grid()
```


**Figura 1.**  (a) Índice de producción nominal de en Colombia sector manufactura,
Clase industrial: otros productos quimicos. Enero 2001 - diciembre 2019; (b) Tendencia según el filtro de descomposición aditiva.


De la Figura 1(a) se deduce la presencia de estacionalidad y tendencia aditivas,  es aditiva dado que su varianza es constante alrededor de su trayectoria de largo plazo(tendencia). En la Figura 1(b) es visible que la serie es de tendencia creciente y que existen ciclos. 


##  grafico de boxplots comparativos de la distribucion de la serie versus perıodos del año calendario

## Periodograma

```{r}
par(mfrow=c(2,2))
boxplot(Datos20~cycle(Datos20), names=month.abb, ylab="Producción nominal", xlab = "Meses del año", sub="(a)")
grid()
periodogram(diff(Datos20),lwd=4, sub="(b)") #periodograma sobre los logaritmos diferenciados
abline(v=c(1:6)/12,col=2,lty=2)
grid()
```


**Figura 2.** (a) Boxplots: distribución por meses de la serie. (b) Periodograma
sobre las diferencias de la serie.

De la figura 2(a) en los boxplots comparativos se ve cómo la media (o mediana) de la distribución de la serie según el periodo del año, cambia a lo largo de un año calendario siendo menor en los meses de enero, febrero, abril y diciembre comparados con el resto del año. Tiene un crecimiento de enero a marzo y luego vuelve y baja en abril  para volver a subir en mayo manteniendose relativamente al mismo nivel en los siguientes meses hasta noviembre, para luego decaer en diciembre y retormar el siguiente año; se confirma que existe un patrón periódico anual con una forma constante en el tiempo.




De la figura 2(b) Periodograma: muestra la asociacion de la serie con cinco componentes periodicas (valor alto del periodograma en esas frecuencias): en las frecuencias 1/12 y 2/12, 3/12, 4/12, 6/12. El periodograma reafirma la existencia de componente estacional.

# justifique por que existe componente estacional y si su forma es constante o no en el tiempo. 

- Mediante el gráfico de la serie vs el tiempo se ve un patrón que se repite cada año; pues en cada año se observa que en los meses del inicio y del final el índice de producción nominal es bajo y tiene aproximadamente 2 picos de decaimiento en el transcurso del año.

- Dado que en el gráfico de boxplot al menos una de las medias de los meses cambia respecto al resto de los meses del año calendario, por lo tanto se concluye que cada periodo en que se divide el año calendario determina una estación, la cual tiene incidencia sobre el valor medio de la serie, por ellos se dice que existe la componente estacional.

- Mediante el periodograma se resalta que hay una asociación de la serie con fenomenos periodicos, indicando la existencia de una componente estacional.


## Es la estacionalidad constante o no en el tiempo:

```{r}
par(mfrow=c(2,2))
plot(Datos20, xlim=c(2001,2005))
grid()
plot(Datos20, xlim=c(2006,2010))
grid()
plot(Datos20, xlim=c(2011,2015))
grid()
plot(Datos20, xlim=c(2016,2019))
grid()

```


## la tendencia se puede ajustar globalmente o si es local.

- La tendencia de la serie es global ya que se puede ajustar una curva suave creciente en todos los tiempos de la serie, También se puede ajustar modelos locales para comparar los ajustes y pronosticos respecto a la ajuste global.



##  identificacion de posibles ciclos y cambios estructurales.

* Hay presencia de ciclos en la serie a tráves del tiempo ya que al aplicar la descomposición aditiva y obtener la tendencia, no se observa una curva suave que describa la tendencia de la serie.
* Hay aproximadamente entre 4 y 5 ciclos en la serie a través del tiempo (montañas).
* Parace haber posible cambio estructural en la serie en el 2015 ya que el nivel de la serie cambia un poco a partir de ese año.




#################################################################################


# Modelos propuestos


Por el análisis descriptivo, para los modelos globales la tendencia puede ser ajustada por un polinomio de grado $p = 2, 3$ y la componente estacional puede representarse como un factor y por tanto usar  variables indicadoras en los modelos globales. Se proponen los siguientes modelos de regresión, donde t es el índice de tiempo y $I_{i,t}$ es la indicadora del trimestre i en el tiempo t.


$$\text{Tabla 1. Ecuación de los modelos propuestos}$$
$$\begin{array}{|c|}
\hline
\text{ Modelo 1: Modelo cuadrático estacional con indicadoras, mes de referencia diciembre}\\
Y_t=\beta_0+\beta_1t+\beta_2t^2+\sum_{i=1}^{11}\delta_iI_{i,t}+E_t, ~~~ E_t \sim iid N(0, \sigma^2)\\
\hline
\text{Modelo 2: Modelo cúbico estacional con indicadoras, mes de referencia diciembre}\\
Y_t=\beta_0+\beta_1t+\beta_2t^2+\beta_3t^3+\sum_{i=1}^{11}\delta_iI_{i,t}+E_t, ~~~ E_t \sim iid N(0, \sigma^2)\\
\hline
\text{Modelos 3: Descomposición aditiva & Loess cuadrático}\\
\text{En la vecindad de un tiempo} ~t_k~ \text{donde se quiere ajustar} 
Y_t = \beta_{0,k} + \beta_{1,k}t + \beta_{2,k}t^2 + \sum_{i=1}^{12}\delta_i I_{i,t} +  E_t, ~~ E_t \sim iid N(0,\sigma^2) \\
\text{para todo t vecino a} ~~t_k,~~ \text{con} \sum_{i=1}^{12}\delta_i=0,~~~ \beta_{0,k},~\beta_{1,k}~y~\beta_{2,k}~~ \text{los parámetros de la parábola local en la vecindad de} ~~t_k\\
\hline
\text{Modelo 4: Suavizamiento exponencial Holt-Winters aditivo}\\
Y_{t+h} = \beta_{0,t} + \beta_{1,t}\times h + \sum_{i=1}^{12}\delta_{i,t} I_{i,t+h} +  E_{t+h}, ~~ E_t \sim iid N(0,\sigma^2),\text{con} \sum_{i=1}^{12}\delta_{i,t}=0,~~\beta_{0,t}~y~\beta_{1,t}~y~\delta_{i,t}, \text{el nivel en} ~~t,~~\\
\text{la pendiente en} ~~t~~ \text{y los efectos estacionales en t, respectivamente, cambiando lentamente en el tiempo.}\\
\hline
\end{array}$$


## Modelo 1: Modelo cuadrático estacional con indicadoras, mes de referencia diciembre

$$Y_t=\beta_0+\beta_1t+\beta_2t^2+\sum_{i=1}^{11}\delta_iI_{i,t}+E_t, ~~~ E_t \sim iid N(0, \sigma^2)$$

## Modelo 2: Modelo cúbico estacional con indicadoras, mes de referencia diciembre

$$Y_t=\beta_0+\beta_1t+\beta_2t^2+\beta_3t^3+\sum_{i=1}^{11}\delta_iI_{i,t}+E_t, ~~~ E_t \sim iid N(0, \sigma^2)$$

## Modelos 3: Descomposición aditiva & Loess cuadrático

En la vecindad de un tiempo $t_k$ donde se quiere ajustar, $Y_t = \beta_{0,k} + \beta_{1,k}t + \beta_{2,k}t^2 + \sum_{i=1}^{12}\delta_i I_{i,t} +  E_t, ~~ E_t \sim iid N(0,\sigma^2)$ para todo t vecino a $t_k$, con $\sum_{i=1}^{12}\delta_i=0,~~~ \beta_{0,k},~\beta_{1,k}~y~\beta_{2,k}$ los parametros de la parabola local en la vecindad de $t_k$


## Modelo 4: Suavizamiento exponencial Holt-Winters aditivo

$Y_{t+h} = \beta_{0,t} + \beta_{1,t}\times h + \sum_{i=1}^{12}\delta_{i,t} I_{i,t+h} +  E_{t+h}, ~~ E_t \sim iid N(0,\sigma^2)$, con $\sum_{i=1}^{12}\delta_{i,t}=0,~~\beta_{0,t}~y~\beta_{1,t}~y~\delta_{i,t}$, el nivel en $t$, la pendiente en $t$ y los efectos estacionales en $t$, respectivamente, cambiando lentamente en el tiempo.


# Ajustes

## Ajuste de los modelos con validación cruzada

Se implementa la estrategia de validación cruzada excluyendo del ajuste los últimos $m = 12$ datos, que comprende de enero de 2001 a diciembre de 2018 por tanto, la validación cruzada se hará con los pronósticos ex-post de estos últimos.



```{r}
m <- 12 # numero de periodos a pronosticar dentro de la muestra
n <-length(Datos20)-m # tamaño de la muestra para el ajuste
t <- 1:n #Indice de tiempo en los periodos de ajuste
```


* Datos para el ajuste:

```{r}
yt <- ts(Datos20[t], frequency = 12, start=c(2001, 1))
```



* Creación de las variables indicadoras para los datos de muestra
```{r}
mes <- seasonaldummy(yt) #Matriz con las 11 primeras variables Indicadoras mes


#Separando una a una las 11 variables indicadoras

I1 <- mes[,1]
I2 <- mes[,2]
I3 <- mes[,3]
I4 <- mes[,4]
I5 <- mes[,5]
I6 <- mes[,6]
I7 <- mes[,7]
I8 <- mes[,8]
I9 <- mes[,9]
I10 <- mes[,10]
I11 <- mes[,11]
```


* Creación de las variables indicadoras para los datos de validación cruzada


```{r}
tnuevo <- (n+1):length(Datos20)
ytnuevo <- ts(Datos20[tnuevo], frequency = 12, start = c(2019, 1))


mesnuevo <- seasonaldummy(yt, h=12)
#Separando una a una las 11 indicadoras para los tiempos de pron?stico
I1n=mesnuevo[,1]
I2n=mesnuevo[,2]
I3n=mesnuevo[,3]
I4n=mesnuevo[,4]
I5n=mesnuevo[,5]
I6n=mesnuevo[,6]
I7n=mesnuevo[,7]
I8n=mesnuevo[,8]
I9n=mesnuevo[,9]
I10n=mesnuevo[,10]
I11n=mesnuevo[,11]
```



## Ajuste del modelo 1 Modelo cuadrático estacional con indicadoras


```{r}
mod1 <- lm(yt~t+I(t^2)+I1+I2+I3+I4+I5+I6+I7+I8+I9+I10+I11)
summary(mod1)
```


$$\begin{array}{| c | c | c | c| c |}
\hline
Parametro&Estimación&Error~Estándar&T_0&P(|T_{202}|>|T_0|)\\
\hline
\beta_0&35.8242551&1.2250562&29.242949&0.0000000\\
\beta_1&0.1319807&0.0174478&7.564309&0.0000000\\
\beta_2&0.0007051&0.0000779&9.055350&0.0000000\\
\delta_1&-3.1817818&1.3273503&-2.397093&0.0174368\\
\delta_2&5.3069465&1.3272009&3.998601&0.0000893\\
\delta_3&12.0220423&1.3270660&9.059114&0.0000000\\
\delta_4&7.2690612&1.3269454&5.478041&0.0000001\\
\delta_5&12.1146698&1.3268389&9.130475&0.0000000\\
\delta_6&9.8255350&1.3267465&7.405736&0.0000000\\
\delta_7&8.4294343&1.3266681&6.353838&0.0000000\\
\delta_8&9.0930346&1.3266037&6.854372&0.0000000\\
\delta_9&12.5163357&1.3265533&9.435230&0.0000000\\
\delta_{10}&10.5493377&1.3265171&7.952659&0.0000000\\
\delta_{11}&8.9475962&1.3264952&6.745291&0.0000000\\
\hline
\end{array}$$





## Ajuste del modelo 2 Modelo cúbico estacional con indicadoras


```{r}
mod2 <- lm(yt~t+I(t^2)+I(t^3)+I1+I2+I3+I4+I5+I6+I7+I8+I9+I10+I11)
summary(mod2)
```


$$\begin{array}{| c | c | c | c| c |}
\hline
Parámetro&Estimación&Error~Estándar&T_0 &P(|T_{201}|>|T_0|)\\
\hline
\beta_0&35.1122117&1.4518673&24.1841735&0.0000000\\
\beta_1&0.1689800&0.0440540&3.8357445&0.0001675\\
\beta_2&0.0002800&0.0004712&0.5943651&0.5529364\\
\beta_3&0.0000013&0.0000014&0.9147258&0.3614316\\
\delta_1&-3.1146344&1.3299145&-2.3419809&0.0201603\\
\delta_2&5.3679308&1.3294103&4.0378283&0.0000767\\
\delta_3&12.0768988&1.3289564&9.0875055&0.0000000\\
\delta_4&7.3178173&1.3285516&5.5081165&0.0000001\\
\delta_5&12.1573451&1.3281951&9.1532824&0.0000000\\
\delta_6&9.8621412&1.3278862&7.4269474&0.0000000\\
\delta_7&8.4599754&1.3276245&6.3722651&0.0000000\\
\delta_8&9.1175066&1.3274098&6.8686450&0.0000000\\
\delta_9&12.5347270&1.3272421&9.4441906&0.0000000\\
\delta_10&10.5616286&1.3271216&7.9582979&0.0000000\\
\delta_11&8.9537593&1.3270487&6.7471217&0.0000000\\
\hline
\end{array}$$



## Funciones a utilizar:

```{r}
#Creando función para extraer correctamente estimaciones de los efectos estacionales 𝜹𝒊 por filtro de descomposición
factoresdeltai=function(descom,s,estacionini){
if(estacionini==1){
deltasi=descom$figure
}
if(estacionini!=1){
j=estacionini;deltasi=c(descom$figure[(s-j+2):s],descom$figure[1:(s-j+1)])
}
deltasi
}
```


## Ajuste modelo 3 Descomposición aditiva & Loess cuadrático


```{r}
#Descomposición aditiva de la serie recortada
descom=decompose(yt,type="additive")
```



```{r}
s=12 #Longitud del periodo estacional
```



```{r}
#Componente estacional estimada de la descomposición de la serie recortada
St=descom$seasonal


deltas_i=factoresdeltai(descom=descom,s=12,estacionini=1) #Obteniendo los s factores estacionales estimados


#el período es s=12 y la serie arranca en estación 1
deltas <- data.frame(deltas_i)

```

En la Tabla se muestra la estimación de los efectos estacionales de acuerdo al filtro de la descomposición aditiva sobre los primeros 216 datos

$$\begin{array}{| c | c | c | c| c |}
\hline
i& \hat{\delta}_i\\
\hline
1&-10.8780433\\
2&-2.3143178\\
3&4.3650940\\
4&-0.5319649\\
5&4.3979371\\
6&2.0783292\\
7&0.7969567\\
8&1.2373979\\
9&4.6148489\\
10&2.5229371\\
11&1.0633783\\
12&-7.3525531\\
\hline
suma & 0\\
\hline
\end{array}$$



```{r}
#Pronósticos para la componente estacional usando estimaciones del filtro de descomposición clásica

#los pronósticos inician en enero 2019 y terminan en diciembre 2019

i=c(1,2,3,4,5,6,7,8,9,10,11,12) #identificando la estación correspondiente a los m=12 períodos de pronósticos
```




```{r}
Stnuevo=deltas_i[i] #Asignando el valor de St a los periodos a pronosticar
Stnuevo=ts(Stnuevo,frequency=12,start=c(2019,1)) #convirtiendo en serie de tiempo al pronóstico de St
Stnuevo
```

```{r}
#Desestacionalizando o ajustando estacionalmente a la serie recortada, según modelo aditivo
ytd=yt-St
```



```{r}
#LOESS cuadrático (AICC) sobre serie desestacionalizada
mod3=loess.as(t,ytd,degree=2,criterion="aicc",family="gaussian",plot=F)
summary(mod3)
alfa.optim2=mod3$pars$span #guardando el valor óptimo del parámetro alfa
```




## Ajuste modelo 4 con método Suavizamiento exponencial Holt-Winters aditivo

### Modelo de tendencia con cambio de nivel y pendiente, aditiva a factor estacional con efectos que evolucionan lentamente en el tiempo

```{r}
mod4=HoltWinters(yt,seasonal="additive") #Suavizamiento con valores Optimos en parametros 𝜶, 𝜷, 𝜸
mod4
```




$$\begin{array}{| c | c | c | c| c |}
\hline\\
\hline
alpha:\alpha &0.2279994\\
beta:\beta &0.010042\\
gamma:\gamma &0.397323\\
\hline\\\hline
a:\hat{\beta}_{0,216}&101.9644720\\
b:\hat{\beta}_{1,216}&0.2949128\\
s1: \hat{\delta}_{1,216}&-12.3938476\\
s2: \hat{\delta}_{2,216}&-2.0117762\\
s3: \hat{\delta}_{3,216}& 3.6989236\\
s4: \hat{\delta}_{4,216}& 0.1017724\\
s5: \hat{\delta}_{5,216}& 6.8427850\\
s6: \hat{\delta}_{6,216}& 4.2348284\\
s7: \hat{\delta}_{7,216}& 2.7412904\\
s8: \hat{\delta}_{8,216}& 6.6698440\\
s9: \hat{\delta}_{9,216}&10.1574426\\
s10: \hat{\delta}_{10,216}&6.3504048\\
s11: \hat{\delta}_{11,216}&4.5463245\\
s12: \hat{\delta}_{12,216}&-9.2424032\\
\hline
\end{array}$$

# Ecuaciones ajustadas en modelos globales. Ecuaciones de suavizamiento Holt-Winters. Ajuste componente estacional por filtro de descomposición



$$\begin{array}{| c | c | c | c| c |}
\hline
Modelo & Ecuación \\
\hline
1 & \hat{Y}_t \approx 35.8242551 + 0.1319807 t + 0.0007051 t^2	- 3.1817818 I_{1,t} + 5.3069465 I_{2,t} + 12.0220423 I_{3,t}+ 7.2690612 I_{4,t}+\\
& 12.1146698 I_{5,t}+ 9.8255350 I_{6,t}+ 8.4294343 I_{7,t} + 9.0930346 I_{8,t}+ 12.5163357 I_{9,t}+ 10.5493377 I_{10,t}+ 8.9475962 I_{11,t}\\
\hline
2 & \hat{Y}_t \approx 35.1122117 + 0.1689800 t + 0.0002800 t^2	+ 0.0000013 t^3 - 3.1146344 I_{1,t} + 5.3679308 
I_{2,t}+ 12.0768988 I_{3,t}+ \\
& 7.3178173 I_{4,t}+ 12.1573451 I_{5,t}+ 9.8621412 I_{6,t}+ 8.4599754 I_{7,t} +  9.1175066 I_{8,t}+ 12.5347270 I_{9,t}+ 10.5616286 I_{10,t}+ 8.9537593 I_{11,t}\\
\hline
3 & \hat{S}_t = \sum_{i=1}^{11}{\hat{\delta_i}I_{i,t}} =  -10.8780433 I_{1,t} - 2.3143178 I_{2,t} + 4.3650940 I_{3,t} - 0.5319649 I_{4,t}
 +4.3979371\\ 
& I_{5,t}+ 2.0783292 I_{6,t}+ 0.7969567 I_{7,t} + 1.2373979 I_{8,t}+ 4.6148489 I_{9,t}+ 2.5229371 I_{10,t}+ 1.0633783 I_{11,t}- 7.3525531 I_{12,t}\\
\hline
4 & \beta_{0,t} = 0.2279994(Y_t - \hat{S}_{t-12}) +  0.7720006(\hat{\beta}_{0,t-1} + \hat{\beta}_{1,t-1})\\
& \hat{\beta}_{1,t} = 0.010042(\hat{\beta}_{0,t} - \hat{\beta}_{0,t-1}) + 0.989958\hat{\beta}_{1,t-1}\\
&  \hat{S}_t = 0.397323(Y_t-\hat{\beta}_{0,t}) + 0.602677\hat{S}_{t-12}\\
& \hat{Y}_t = (\beta_{0,t-1} + \hat{\beta}_{1,t-1}) + \hat{S}_{t-12}\\
\hline
\end{array}$$




# Valores ajustados de los modelos 


Modelo 1

```{r}
mod1_ajust <- ts(fitted(mod1), start  = c(2001,1), frequency = 12)
```


```{r}
plot(Datos20)
lines(mod1_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste del modelo1"), lty=1, col=c(1,2))

```

Modelo 2

```{r}
mod2_ajust <- ts(fitted(mod2), start  = c(2001,1), frequency = 12)
```


```{r}
plot(Datos20)
lines(mod2_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste del modelo2"), lty=1, col=c(1,2))

```

modelo 3

```{r}
mod3_Tt <- ts(fitted(mod3), start  = c(2001,1), frequency = 12)
mod3_ajust <- mod3_Tt + St # Ajuste D&LC(AICC)
```


```{r}
plot(Datos20)
lines(mod3_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste D&LC(AICC)"), lty=1, col=c(1,2))

```




Modelo 4

```{r}
mod4_ajust <- fitted(mod4)[,1]
plot(Datos20)
lines(mod4_ajust, col=2, lwd=2)
legend("topleft", legend=c("Original","Ajuste H-W"), col=c(1,2), lty=1)
```

# Calculo del AIC y BIC

```{r}
#Creando funci?n usuario crit.inf.resid() para calcular C^*_n(p)
crit.inf.resid <- function(residuales,n.par,AIC="TRUE"){
if(AIC=="TRUE"){
#Calcula AIC
CI=log(mean(residuales^2))+2*n.par/length(residuales)
}
if(AIC=="FALSE"){
#Calcula BIC
CI=log(mean(residuales^2))+n.par*log(length(residuales))/length(residuales)
}
CI
}  
```

modelo 1
```{r}
resmod1.orig <- residuals(mod1) #seudo-residuos en la escala original. Usados solo para calcular AIC y BIC

npar1 <- length(coef(mod1)[coef(mod1)!=0]) #numero parametros modelo 1

AIC1 <- exp(crit.inf.resid(resmod1.orig,n.par=npar1))
BIC1 <- exp(crit.inf.resid(resmod1.orig ,n.par=npar1, AIC="FALSE"))
```

modelo 2
```{r}
resmod2.orig <- residuals(mod2) #seudo-residuos en la escala original. Usados s?lo para calcular AIC y BIC

npar2 <- length(coef(mod2)[coef(mod2)!=0]) #n?mero par?metros modelo 1

AIC2 <- exp(crit.inf.resid(resmod1.orig,n.par=npar2))
BIC2 <- exp(crit.inf.resid(resmod1.orig ,n.par=npar2, AIC="FALSE"))
```

modelo 3
```{r}
et3 <- yt - mod3_ajust

p3 <- round(mod3$enp)+s-1
AIC3 <- exp(crit.inf.resid(residuales=et3,n.par=p3))
BIC3 <- exp(crit.inf.resid(residuales=et3,n.par=p3,AIC="FALSE"))
```

modelo 4
```{r}
p4 <- 2+s-1 #Aprox. del n?mero de par?metros del suavizamiento
AIC4 <- exp(crit.inf.resid(residuales=residuals(mod4),n.par=p4))
BIC4 <- exp(crit.inf.resid(residuales=residuals(mod4),n.par=p4,AIC="FALSE"))
```

```{r}
library(kableExtra)
```

```{r}
Modelo <- c(1,2,3,4)
p <- c(npar1, npar2, p3, p4)
AIC <- c(AIC1, AIC2, AIC3, AIC4)
BIC <- c(BIC1, BIC2, BIC3, BIC4)
Criterios_inf <- data.frame(Modelo, p, AIC, BIC) 
```


$$\begin{array}{| c | c | c |}
\hline
Modelo&p&AIC&BIC\\
\hline
1&14&16.85948&20.98234\\
2&15&17.01631&21.51105\\
3&24&11.18417&16.27338\\
4&13&16.87146&20.84412\\
\hline
\end{array}$$

Con relación a la calidad de ajuste, vemos un ajuste muy similar entre los modelos, todos consiguen seguir muy bien los patrones de tendencia, estacionalidad y al parecer también los ciclos. Por otro lado, los valores de AIC y BIC también son similares aunque numéricamente resulta menor el del modelo 3, tanto AIC y BIC coinciden en el mismo modelo. El modelo de regresión cubico con indicadoras tiene el mayor en AIC y BIC (aunque como ya se indicó, el grado del polinomio no es significativo).

#############################################################################

# Preguntas orientadas para los analisis
## hacer tablas de los summary

..............................................................................
 **En los modelos globales ¿Son significativos el polinomio considerado y la componente estacional con la representación que fue usada?**
 
 

Modelo 1

Debido a que el valor ajustado para el coeficiente correspondiente al grado 2 del polinomio tiene un p-valor muy pequeño(menor a 0.05), se dice que es significativo y por lo tanto la estructura del polinomio cuadrático es significativa.
Por otro lado, ya que al menos uno de los coeficientes estimados asociados a las variables indicadoras, son significativos(p-valor menor a 0.05), en este caso todos, se concluye que la componente estacional es significativa.

Modelo 2

Debido a que el valor ajustado para el coeficiente correspondiente al grado 3 del polinomio tiene un p-valor grande(mayor a 0.05), se dice que no es significativo y por lo tanto la estructura del polinomio cúbico no es significativa.
Por otro lado, ya que al menos uno de los coeficientes estimados asociados a las variables indicadoras, son significativos(p-valor menor a 0.05), en este caso todos, se concluye que la componente estacional es significativa.


Conclusión:

Desarrollando los tests enunciados en la Tabla de hipotesis, con base en resultados, se concluye que el modelo1 global es significativo el respectivo polinomio propuesto (aunque esto no implica que el modelo es correcto), en cambio el modelo2 no es significativo respecto al polinomio propuesto. Para la componente estacional, a un nivel de significancia de 0.05, en ambos modelos se concluye que todos los $\delta_i$ son estadísticamente significativos,  incluso siendo solo uno de ellos significativo es suficiente para afirmar que la componente estacional modelada globalmente como un factor, es estadísticamente significativa.
..............................................................................

**En los modelos globales ¿Cuál es la interpretación de las estimaciones de los parámetros estacionales?**

Ya que la serie es aditiva, los $\delta_i$ es la diferencia entre la media de la serie en el mes i del año menos la media en el periodo de referencia, es decir, diciembre.

Interpretación del $\delta_1=-3.18178$ en el modelo 1:

* El modelo 1 estima que en promedio del indice de producción nominal en el mes de enero disminuyo en 3.18178 unidades en comparación con el del mes de diciembre en cada año.


$$\begin{array}{| c | c | c |}
\hline
\delta~i&Modelo~1&Modelo~2\\
\hline
\delta_1&-3.181782&-3.114634\\
\delta_2&5.306946&5.367931\\
\delta_3&12.022042&12.076899\\
\delta_4&7.269061&7.317817\\
\delta_5&12.114670&12.157345\\
\delta_6&9.825535&9.862141\\
\delta_7&8.429434&8.459975\\
\delta_8&9.093035&9.117507\\
\delta_9&12.516336&12.534727\\
\delta_{10}&10.549338&10.561629\\
\delta_{11}&8.947596&8.953759\\
\hline
\end{array}$$



**¿difieren mucho estas estimaciones entre los modelos globales?**

* Las estimaciones de los parámetro asociados a la variables indicadora que modelan la estacionalidad difieren minimamente en los modelos globales.


**Además, si se modelo con variables indicadoras, grafique en un mismo plano y en la escala original de la serie, el patrón estacional estimado ¿Estas estimaciones aproximan apropiadamente el patrón estacional? Esta gráfica puede realizarse de la siguiente manera: Suponga que los modelos son ajustados en R bajo los objetos de nombre mod1 y mod2 respectivamente. Sean p1 y p2 los ordenes de los respectivos polinomios, nparmod1 y nparmod2 el número de parámetros, de cada modelo, respectivamente. En el caso aditivo, proceda así:**



```{r}
p1 <- 2 # grado del polinomio modelo 1
p2 <- 3 # grado del polinomio modelo 2


efectosestac1 <- ts(c(coef(mod1)[(p1+2):npar1],0),freq=1,start=1)
efectosestac2 <- ts(c(coef(mod2)[(p2+2):npar2],0),freq=1,start=1)
plot(efectosestac1,lwd=4,ylab="",xlab="Periodo del año", col="blue")
lines(efectosestac2,lty=2,col="cyan4",lwd=4)
grid()
legend("topleft",legend=c("Modelo 1","Modelo 2"),col=c("blue", "cyan4"),lty=1:2,lwd=2)
```


Vemos que el mod1 y el mod2 estiman la misma forma para $S_t$ además de que sus valores son muy similares para los efectos estacionales (no son iguales pero tinen diferencias muy pequeñas en las estimaciones de los $\delta_i$)

* Mediante el gráfico se puede notar que las estimación del $\delta_1$ que es el del mes de enero es la única con valor negativo, es decir es el único mes donde la producción nominal tuvo una disminución respecto al mes de diciembre que es el de referencia, por lo tanto para el resto de meses de febrero a noviembre tuvo un aumento en comparación con el mes de diciembre (Este es un comportamiento dentro de cada año).

* Se puede visualizar mediante la gráfica que la estimación del $\delta$ para el mes 12 es decir de diciembre toma el valor de cero, debido a que es el mes de referencia.

.............................................................................



 **Compare gráficamente la forma de la estimación de la componente estacional entre los dos modelos locales(en Holt-Winters se toma el  último valor suavizado para cada uno de los 12 efectos estacionales) ¿difieren mucho? Además, si en los modelos globales se usaron indicadoras, compare la forma del patrón estacional estimado por estos vs. los locales ¿qué se interpreta a partir de la similaridad o diferencia entre estas estimaciones?**
 
 
```{r}
#extracción estimaciones en t=216 de efectos estacionales segun Holt-Winters.

deltasiHW=ts(mod4$coef[c(3:14)],freq=1,start=1)#Estimaciones de los efectos estacionales segun filtro de descomposicióon

deltasDescomp=ts(deltas_i,freq=1,start=1)
deltasilocales=data.frame(rbind(deltasiHW,deltasDescomp),row.names=c("HW","Descomp&loess"))
names(deltasilocales)=c(1:12)#Gráfico de los efectos estacionales estimados


plot(deltasiHW,lwd=4,ylim=c(min(deltasiHW,deltasDescomp),max(deltasiHW,deltasDescomp)+0.05),ylab="",xlab="Mes del año")
lines(deltasDescomp,lty=2,lwd=4,col=2)
grid()
legend("topleft",legend=c("Efectos estacionales H-W en t=216","Efectos estacionales Filtro de descomposición"),col=1:2,lty=1:2,lwd=3, cex=0.7)
```

* En esta figura vemos que la forma del patrón estacional que estima al final Holt-Winters y el que estima globalmente el filtro de la descomposición, es muy similar aunque se observan algunas diferencias que destacan para los meses de
mayo a noviembre, periodos del año en los que Holt-Winters termina con estimaciones mayores a las del filtro. Podemos decir que dado lo anterior, la forma del patrón estacional es más o menos estable y que en esta componente
las proyecciones en los pronósticos ex–post del filtro y de Holt-Winters, no distan mucho.



```{r}
plot(efectosestac1,lwd=3, col="blue", xlab="Periodo del año", ylim =c(-10,23))
lines(efectosestac2,lty=2,col="cyan4",lwd=4)
lines(deltasiHW,lwd=3, col=3)
lines(deltasDescomp,lty=2,lwd=4,col="purple")
grid()
legend("topleft",legend=c("Polinomial cuadrático","Polinomial cúbico", "SEHW","DLC"),col=c("blue", "cyan4", 3, "purple"),lwd=3, cex=0.8)
```


* Vemos que los modelos globales respecto a los locales estiman la misma forma de $S_t$ pero con valores diferentes de los efectos estacionales al no coindir los $\delta_i$

..............................................................................


**Con relación al ajuste loess de la serie desestacionalizada ¿Qué se concluye de su gráfica y del número de parámetros equivalentes loess?**
 
# GRÁFICOS DE LA SERIE DESESTACIONALIZADA Y SUS AJUSTES LOESS

```{r}
plot(ytd, ylab="")
lines(mod3_Tt, col=2, lwd = 2)
grid()
legend("topleft", legend=c("Serie ajustada estacionalmente", "Tendencia LOESS cuadrático (AICC)"), col=c(1,2), lty=1)
``` 


Se observa que los valores ajustados se acercan a los valores que toma la serie; la componente ciclica que toma la serie esta presente ya que se puede observar que la tendencia no es una curva completamente suave. 

Finalmente el ajuste que hace LOESS al final de la serie es creciente, aunque el valor real muestra una tendencia decreciente

Para un ajuste global polinomial alcanzando el mismo ajuste que LOESS, el modelo global deberia ser un polinomial con aproximadamente 13 parámetros.

.............................................................................


**¿Qué se concluye sobre la calidad del ajuste de los modelos globales vs. locales? también determine entre los modelos globales cuál modelo recomendaría inicialmente como mejor modelo global para ajustar la serie. Tenga en cuenta no sólo los valores de los criterios de información, sino también los resultados gráficos.**

(En las diapositivas colocar nuevamente las graficas de ajuste y la tabla de los criterios de información)


```{r}
par(mfrow=c(2,2))
plot(Datos20)
lines(mod1_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste del modelo1"), lty=1, col=c(1,2), cex=0.5)

plot(Datos20)
lines(mod2_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste del modelo2"), lty=1, col=c(1,2), cex=0.5)

plot(Datos20)
lines(mod3_ajust, col=2, lwd=2)
legend("topleft", legend = c("Original", "Ajuste D&LC(AICC)"), lty=1, col=c(1,2), cex=0.5)

plot(Datos20)
lines(mod4_ajust, col=2, lwd=2)
legend("topleft", legend=c("Original","Ajuste H-W"), col=c(1,2), lty=1, cex=0.5)
```



* En general mediante los gráficos tiene un mejor ajuste los modelos locales que los globales


*  Entre los modelos globales se recomienda el modelo cuadrático con indicadoras ya que con un grado menos del polinomio ajusta igual de bien que el cúbico, por tanto se prefiere por ser un modelo más simple (parsimonioso) además que en los ajustes se noto que el grado 3 del polinomio del segundo modelo no es significativo.

* Mediante los criterios del AIC y BIC se prefiere al modelo 3 (DLC) dado que es el de menor valor

* Mediante el AIC y BIC de los modelos globales se escoge modelo2 (cuadrático) dado que toma los menores valores en estos criterios de información.

..............................................................................


# 4. Análisis de residuales y validación de supuestos: Para todos los modelos ajustados, globales y locales, realice el análisis comparativo de residuales.


Gráfico de los residuales en el tiempo

```{r}
par(mfrow=c(2,2))

# Residuales vs tiempo mod1
plot.ts(residuals(mod1))
abline(h=c(-2*summary(mod1)$sigma, 0, 2*summary(mod1)$sigma), col=2)
legend("topleft", legend=c("Modelo1"), lty=1, col = 1, lwd=2)


# Residuales vs tiempo mod2
plot.ts(residuals(mod2))
abline(h=c(-2*summary(mod2)$sigma, 0, 2*summary(mod2)$sigma), col=2)
legend("topleft", legend=c("Modelo2"), lty=1, col = 1, lwd=2)


# Residuales vs tiempo mod3
df=n-(round(mod3$enp)+s-1) #Grados de libertad aproximados del ajuste total
MSE3=sum(et3^2)/df #MSE aproximado del ajuste total del modelo 3
plot(et3,ylim=c(min(-2*sqrt(MSE3),et3),max(2*sqrt(MSE3),et3)))
abline(h=c(-2*sqrt(MSE3),0,2*sqrt(MSE3)),col=2)
legend("topleft", legend=c("Modelo3"), lty=1, col = 1, lwd=2)


# Residuales vs tiempo mod4

et4=residuals(mod4)
df4=n-2*s-((s-1)+2)
MSE4=mod4$SSE/df4 #MSE aproximado del ajuste total del Suavizamiento

plot(et4,ylim=c(min(-2*sqrt(MSE4),et4),max(2*sqrt(MSE4),et4)))
abline(h=c(-2*sqrt(MSE4),0,2*sqrt(MSE4)),col=2)
legend("topleft", legend=c("Modelo4"), lty=1, col = 1, lwd=2)



```

```{r}

par(mfrow=c(2,2))
# Residuales vs valores ajustados mod1

plot(fitted(mod1), residuals(mod1))
abline(h=c(-2*summary(mod1)$sigma, 0, 2*summary(mod1)$sigma), col=2)
legend("topleft", legend=c("Modelo1"), lty=1, col = 1, lwd=2,cex = 0.8)


# Residuales vs valores ajustados mod2

plot(fitted(mod2), residuals(mod2))
abline(h=c(-2*summary(mod2)$sigma, 0, 2*summary(mod2)$sigma), col=2)
legend("topleft", legend=c("Modelo2"), lty=1, col = 1, lwd=2,cex = 0.8)

# Residuales vs valores ajustados mod3
plot(as.numeric(mod3_ajust),et3,ylim=c(min(-2*sqrt(MSE3),et3),max(2*sqrt(MSE3),et3)))
abline(h=c(-2*sqrt(MSE3),0,2*sqrt(MSE3)),col=2)
legend("topleft", legend=c("Modelo3"), lty=1, col = 1, lwd=2,cex = 0.8)

# Residuales vs valores ajustados mod4

plot(as.numeric(mod4_ajust),et4,ylim=c(min(-2*sqrt(MSE4),et4),max(2*sqrt(MSE4),et4)))
abline(h=c(-2*sqrt(MSE4),0,2*sqrt(MSE4)),col=2)
legend("topleft", legend=c("Modelo4"), lty=1, col = 1, lwd=2,cex = 0.8)
```

**Sobre el supuesto de media cero para los errores de ajuste ¿qué se concluye en los cuatro modelos?**

En las figuras presentadas en las gráficas de residuos vs. tiempo y vs. valores ajustados, no se observa evidencia contra el supuesto de que los errores tienen media cero (a pesar de la variación cíclica alrededor de cero, que se observa en las series de tiempo de los residuos de los modelos globales), pues en todos los casos los residuos parecen bien centrados en cero.


* ¿Es válido el supuesto de varianza constante en los 4 modelos?

Se observa una distribución relativamente homogénea de los residuos alrededor de cero, es decir, no hay evidencias contrariando el supuesto de varianza constante para los errores de ajuste. 


* ¿Hay patrones en los residuos que indiquen carencia de ajuste de los modelos en la tendencia y/o la estacionalidad?

No hay evidencia de carencia de ajuste en las componentes estructurales (o sea en tendencia y estacionalidad), pues en los residuos vs. valores ajustados no se observan patrones claros con forma de U o de W que indiquen mal ajuste de la tendencia, ni patrones periódicos en las gráficas de las series de tiempo de residuos de ajuste que indiquen mal ajuste de la estacionalidad.


* ¿Hay ciclos presentes en los residuales? ¿qué se deriva de estos patrones?

En las series de tiempo de los residuos de los modelos globales hay evidencia de ciclos no explicados (los cuales se dan centrados en cero), esto implica que los errores en los modelos globales, separados un periodo en el tiempo, están positivamente correlacionados, es decir, $Corr(E_t,E_{t+1}) > 0$, por lo cual ya no es válido el supuesto de independencia.

Por el contrario, en las series de tiempo de los residuos de los dos modelos locales no son observables a simple vista patrones cíclicos, aunque esto no es una garantía suficiente para afirmar la validez de la independencia entre los errores de ajuste de estos dos modelos, es un punto su favor.


* ¿Qué hacen mejor los métodos locales vs. los globales

En general todos los modelos parecen no tener evidencia en contra de los supuestos de media cero y varianza constante, por lo que esto es positivo pero los métodos locales logran seguir ciclos, por eso son mejores que los modelos globales.


* ¿Cuál es el mejor modelo de los cuatro, de acuerdo al análisis de los residuales?

Con todo lo antes dicho, de los 4 modelos, se considera que los modelos de ajuste local son mejores, ya que en ellos no hay patrones cíclicos y por tanto dan indicios de no incumplir el supuesto de independencia.

* Si es necesario elegir entre los locales, hasta el momento se prefiere el modelo 3 ya que le fue bien los supuestos del modelo y fue el mejor en los ajustes, solo queda mirar en los pronosticos para garantizar de que es el mejor.

...................................................................................


# 5. Pronósticos para la validación cruzada: Para todos los modelos de ajuste global y local presentados, presente los resultados y análisis de pronósticos puntuales y por intervalos.



$$\begin{array}{| c | c | c | c| c |}
\hline
Modelo & Ecuaciones~de~Pronósticos \\
\hline
1 & \hat{Y}_{216}(L) \approx 35.8242551 + 0.1319807 (216+L) + 0.0007051 (216+L)^2	- 3.1817818 I_{1,216+L} +\\
& 5.3069465 I_{2,216+L} + 12.0220423 I_{3,216+L}+ 7.2690612 I_{4,216+L}+ 12.1146698 I_{5,216+L}+ 9.8255350 I_{6,216+L}+\\
& 8.4294343 I_{7,216+L} + 9.0930346 I_{8,216+L}+ 12.5163357 I_{9,216+L}+ 10.5493377 I_{10,216+L}+ 8.9475962 I_{11,216+L}\\
\hline
2 & \hat{Y}_{216}(L) \approx 35.1122117 + 0.1689800 (216+L) + 0.0002800 (216+L)^2	+ 0.0000013 (216+L)^3 - 3.1146344 I_{1,216+L} +\\
& 5.3679308I_{2,216+L}+ 12.0768988 I_{3,216+L}+ 7.3178173 I_{4,216+L}+ 12.1573451 I_{5,216+L}+ 9.8621412 I_{6,216+L}+\\
& 8.4599754 I_{7,216+L} +  9.1175066 I_{8,216+L}+ 12.5347270 I_{9,216+L}+ 10.5616286 I_{10,216+L}+ 8.9537593 I_{11,216+L}\\
\hline
3 & \hat{Y}_{216}(L) = \left(\hat{\beta}_{0,216} + \hat{\beta}_{1,216}(216+L) + \hat{\beta}_{2,216}(216+L)^2\right)+ \left(-10.8780433 I_{1,216+L} - 2.3143178 I_{2,216+L}\\ + 4.3650940 I_{3,216+L}
- 0.5319649 I_{4,216+L}+ 4.3979371 I_{5,216+L}+ 2.0783292 I_{6,216+L}+ 0.7969567 I_{7,216+L}\\ + 1.2373979 I_{8,216+L}+ 4.6148489 I_{9,216+L}+ 2.5229371 I_{10,216+L}+ 1.0633783 I_{11,216+L} - 7.3525531 I_{12,216+L}\right)\\
\hline
4 & \hat{Y}_{216}(L) = (101.9644720 + 0.2949128\times L)+(-12.3938476I_{1,216+L} - 2.0117762I_{2,216+L} + 3.6989236I_{3,216+L} +\\ & 0.1017724I_{4,216+L} + 6.8427850 I_{5,216+L}+ 4.2348284 I_{6,216+L}+ 2.7412904 I_{7,216+L} + 6.6698440 I_{8,216+L}+\\
& 10.1574426 I_{9,216+L} + 6.3504048 I_{10,216+L} + 4.5463245 I_{11,216+L} - 9.2424032 I_{12,216+L})\\
\hline
\end{array}$$

#### Hacer tabla de ecuaciones de pronóstico
#### Tabla con los pronósticos

Valores reales 
```{r}
ytnuevo
```

$$\begin{array}{| c | c | c | c| c |}
\hline
Ene&Feb&Mar&Abr&May&Jun&Jul&Ago&Sep&Oct&Nov&Dic\\
\hline
87.3&102.1&108.5&104.0&112.0&103.3&110.3&109.4&112.1&114.7&109.2&103.3\\
\hline
\end{array}$$



```{r}
kable(data.frame(ytnuevo))
```


Modelo 1

```{r}
ytpron1 <- predict(mod1, newdata=data.frame(t=tnuevo, I1=I1n, I2=I2n, I3=I3n, I4=I4n, I5=I5n, I6=I6n, I7=I7n, I8=I8n, I9=I9n, I10=I10n, I11=I11n), interval="prediction")
ytpron1 <- ts(ytpron1,freq=12,start=c(2019,1))
ytpron1
```


$$\begin{array}{| c | c | c | c| c |}
\hline
Periodo&L&Pronósticos&Lim.Inf&Lim.Sup\\
\hline
Ene~2019&1&94.4852&86.27520&102.6952\\
Feb~2019&2&103.4126&95.19741&111.6279\\
Mar~2019&3&110.5678&102.34725&118.7884\\
Abr~2019&4&106.2564&98.03028&114.4825\\
May~2019&5&111.5449&103.31316&119.7767\\
Jun~2019&6&109.7001&101.46257&117.9377\\
Jul~2019&7&108.7498&100.50627&116.9933\\
Ago~2019&8&109.8606&101.61094&118.1102\\
Sep~2019&9&113.7324&105.47658&121.9883\\
Oct~2019&10&112.2154&103.95319&120.4777\\
Nov~2019&11&111.0651&102.79632&119.3338\\
Dic~2019&12&102.5703&94.29486&110.8457\\
\hline
\end{array}$$



Modelo 2

```{r}
ytpron2 <- predict(mod2, newdata=data.frame(t=tnuevo, I1=I1n, I2=I2n, I3=I3n, I4=I4n, I5=I5n, I6=I6n, I7=I7n, I8=I8n, I9=I9n, I10=I10n, I11=I11n), interval="prediction")
ytpron2 <- ts(ytpron2,freq=12,start=c(2019,1))
ytpron2
```


$$\begin{array}{| c | c | c | c| c |}
\hline
Periodo&L&Pronósticos&Lim.Inf&Lim.Sup\\
\hline
Ene~2019&1&95.19725&86.84148&103.5530\\
Feb~2019&2&104.15594&95.78241&112.5295\\
Mar~2019&3&111.34331&102.95097&119.7356\\
Abr~2019&4&107.06490&98.65269&115.4771\\
May~2019&5&112.38738&103.95418&120.8206\\
Jun~2019&6&110.57743&102.12208&119.0328\\
Jul~2019&7&109.66281&101.18411&118.1415\\
Ago~2019&8&110.81020&102.30691&119.3135\\
Sep~2019&9&114.71959&106.19043&123.2487\\
Oct~2019&10&113.24098&104.68463&121.7973\\
Nov~2019&11&112.12994&103.54501&120.7149\\
Dic~2019&12&103.67534&95.06044&112.2903\\
\hline
\end{array}$$



Modelo 3

```{r}
#Pronósticos de la tendencia por loess cuadrático óptimo (AICC)
Ttnuevo3 <- predict(loess(ytd~t,span=alfa.optim2,degree=2,control=loess.control(surface="direct")),
data.frame(t=tnuevo),se=FALSE)
Ttnuevo3 <- ts(Ttnuevo3,freq=12,start=c(2019,1)) #convirtiendo en serie de tiempo al pronóstico de Tt, modelo 3
ytpron3 <- Ttnuevo3 + Stnuevo #Pronóstico puntual Modelo 2
#Tabla con pronósticos de las componentes y de la serie, Modelo 2
tablapron3 <- cbind(Pron_Tt=Ttnuevo3,Pron_St=Stnuevo,Pron_serie=ytpron3)
tablapron3
```

$$\begin{array}{| c | c | c | c| c |}
\hline
Fecha&L&\hat{T}_{216}(L)&\hat{S}_{216}(L)&\hat{Y}_{216}(L)=\hat{T}_{216}(L)+\hat{S}_{216}(L)\\
\hline
Ene~2019&1&103.9982&-10.8780433&93.12013\\
Feb~2019&2&104.6239&-2.3143178&102.30959\\
Mar~2019&3&105.2877&4.3650940&109.65277\\
Abr~2019&4&105.9900&-0.5319649&105.45802\\
May~2019&5&106.7313&4.3979371&111.12925\\
Jun~2019&6&107.5121&2.0783292&109.59040\\
Jul~2019&7&108.3326&0.7969567&109.12959\\
Ago~2019&8&109.1933&1.2373979&110.43074\\
Sep~2019&9&110.0945&4.6148489&114.70934\\
Oct~2019&10&111.0364&2.5229371&113.55930\\
Nov~2019&11&112.0192&1.0633783&113.08259\\
Dic~2019&12&113.0433&-7.3525531&105.69070\\
\hline
\end{array}$$



Modelo 4

```{r}
pronos4 <- predict(mod4, n.ahead=12,prediction=T,level=0.95)
ytpron4 <- pronos4[,1] #sólo los pronósticos puntuales del suavizamiento
```

$$\begin{array}{| c | c | c | c| c |}
\hline
Periodo&L&Pronósticos&Lim.Sup&Lim.Inf\\
\hline
Ene~2019&1&89.86554&97.40692&82.32415\\
Feb~2019&2&100.54252&108.28129&92.80375\\
Mar~2019&3&106.54813&114.48318&98.61309\\
Abr~2019&4&103.24590&111.37622&95.11557\\
May~2019&5&110.28182&118.60654&101.95710\\
Jun~2019&6&107.96878&116.48710&99.45046\\
Jul~2019&7&106.77015&115.48136&98.05894\\
Ago~2019&8&110.99362&119.89709&102.09014\\
Sep~2019&9&114.77613&123.87132&105.68094\\
Oct~2019&10&111.26400&120.55041&101.97759\\
Nov~2019&11&109.75484&119.23204&100.27763\\
Dic~2019&12&96.26102&105.92865&86.59339\\
\hline
\end{array}$$




Preguntas orientadas

**¿Cuál es la interpretación de los pronósticos puntuales y sus I.P? Ejemplificar con una fecha y comparar entre modelos.**

* Los pronósticos puntuales, indican el valor que cada modelo ajustado con los primeros n = 216 datos, predice que será observado para la serie en cada periodo de los pronósticos ex-posts.

* Los pronósticos por intervalos, indican que el valor real estará en el intervalo de cada uno de los modelos con una confianza del 95%.

La producción nominal de la clase industrial otros productos químicos para el mes de Junio de 2019, comparado con los meses del año 2018 es de:

+ En el __modelo global cuadrático__ : 109.59040 % es decir, durante este periodo aumentó un 9.59%. Además, con un 95% de confianza el valor real del índice se encuentra entre 101.46257 y 117.9377. 

+ En el __modelo global cúbico__ : 110.57743% es decir, durante este periodo aumentó aproximadamente un 10.57%. Además, con un 95% de confianza el valor real del índice se encuentra entre 102.12208 y 119.0328 .

+ En el __modelo local con Descomposición aditiva & Loess cuadrático (DLC)__ : 109.12959 es decir, durante este periodo aumentó aproximadamente un 9.13%.

+ En el __modelo local aditivo con SEHW__: 107.96878% es decir, durante este periodo aumentó aproximadamente un 7.9%. Además, con un 95% de confianza el valor real del índice se encuentra entre 99.45046 y 116.48710  



**¿Cuál es la interpretación de las medidas MAE, MAPE y RMSE? ¿según estas medidas cuál modelo pronostica mejor?**


# Medidas en todos los modelos

```{r}
a <-accuracy(ytpron1,ytnuevo) #Modelo 1
b <- accuracy(ytpron2,ytnuevo) #Modelo 2
c <- accuracy(ytpron3,ytnuevo) #Modelo 3
d <- accuracy(ytpron4,ytnuevo) #Modelo 4

rbind(a,b,c,d)
```

Interpretaciones:

  - Modelo 1:
  
  En promedio en cada pronostico se estima un error de +- 3.153708 puntos del indice de producción nominal según el RMSE y de +- 2.366654 puntos del indice de producció nominal según MAE, mientras que MAPE estima que en promedio cada pronostico se comete un error de +-2.338% con relación al valor real del indice de producción nominal, todo esto en el modelo de regresión cuadrático con variables indicadores
  
     
  - Modelo 2:
  
  En promedio en cada pronostico se estima un error de +- 3.620468 puntos del indice de producción nominal según el RMSE y de +- 2.746457 puntos del indice de producció nominal según MAE, mientras que MAPE estima que en promedio cada pronostico se comete un error de +- 2.71% con relación al valor real del indice de producción nominal, todo esto en el modelo de regresión cúbico con variables indicadores.
  
  
   - Modelo 3:
  
  En promedio en cada pronostico se estima un error de +- 3.014298 puntos del indice de producción nominal según el RMSE y de +- 2.33551 puntos del indice de producció nominal según MAE, mientras que MAPE estima que en promedio cada pronostico se comete un error de +- 2.28% con relación al valor real del indice de producción nominal, todo esto en el modelo de Filtro de decomposición combinado Loess cuadrático.
  
  
   - Modelo 4:
  

  En promedio en cada pronostico se estima un error de +- 3.187973 puntos del indice de producción nominal según el RMSE y de +- 2.670446 puntos del indice de producció nominal según MAE, mientras que MAPE estima que en promedio cada pronostico se comete un error de +- 2.53% con relación al valor real del indice de producción nominal, todo esto en el modelo de SEHW.
  
R/ Según las medidas de pronósticos el mejor modelo es el modelo 3(Usa filtro de descomposición con loess cuadrático)
  
  
**Con base en la amplitud media y cobertura de los I.P ¿qué se concluye?**


(... Tablas de amplitud y cobertura en los modelos ...)


```{r}
#Creando función usuario amplitud() para calcular la amplitud promedio de los I.P en pronósticos ex – post
amplitud=function(LIP,LSP){
a=LSP-LIP
am=mean(a)
am
}
#Creando función usuario cobertura() para calcular la cobertura de los I.P en pronósticos ex – post
cobertura=function(real,LIP,LSP){
I=ifelse(real>=LIP & real<=LSP,1,0)
p=mean(I)
p
}
```


Modelo 1:

```{r}
amplitud(LIP=ytpron1[,2],LSP=ytpron1[,3])
cobertura(real=ytnuevo,LIP=ytpron1[,2],LSP=ytpron1[,3])
```


Modelo 2:


```{r}
amplitud(LIP=ytpron2[,2],LSP=ytpron2[,3])
cobertura(real=ytnuevo,LIP=ytpron2[,2],LSP=ytpron2[,3])
```

Modelo 4:

```{r}
#Precisión pronósticos por I.P Holt-Winters

amplitud(LIP=pronos4[,3],LSP=pronos4[,2])
cobertura(real=ytnuevo,LIP=pronos4[,3],LSP=pronos4[,2])
```

Según este criterio todos los modelos que tienen intervalo de predicción tienen una cubertura del 100%, es decir todos los valores reales caen en el intervalo.

El modelo 1 es el de menor amplitud, por lo tanto según este criterio seria el mejor modelo.




$$\begin{array}{| c | c | c | c| c |}
\hline
RMSE & MAE & MAPE & Amplitud & Cobertura()\\
3.153708&2.366654&2.338060&16.48278&100\\
3.620468&2.746457&2.711682&16.94829&100\\
3.014298&2.335510&2.283224&-&-\\
3.187973&2.670446&2.533667&17.22162&100\\
\hline
\end{array}$$



* ¿Qué se concluye de la figura comparativa de los pronósticos puntuales?


```{r}
plot(ytnuevo,lwd=2, col=1, type="b", pch=1, xlab="Periodo del año", ylab="")
lines(ytpron1[,1],lwd=2, col=2, type="b", pch=2)
lines(ytpron2[,1],lwd=2, col=3, type="b", pch=3)
lines(ytpron3,lwd=2,col=4, type="b", pch=4)
lines(ytpron4,lwd=2,col=5, type="b", pch=5)
grid()
legend("bottomright",legend=c("Real","Pronostico modelo1", "Pronostico modelo2", "Pronostico modelo3", "Pronostico modelo4"),col=1:5,lwd=2, pch=1:5, cex=0.8)
```

* En base a la gráfica de pronosticos se escoge como mejor modelo el modelo 3.


# 6. Conclusiones del trabajo: 

En esta sección debe presentar un resumen de los resultados encontrados en el respectivo trabajo, así como enunciar los problemas enfrentados en la modelación, postular cuál ha sido el mejor modelo en ajuste y pronóstico entre los tratados y comentar acerca de lo que usted crea que logró este mejor modelo:

* ¿Capturó la dinámica de la serie?

* ¿Su tendencia, estacionalidad y sus variaciones cíclicas son bien ajustadas?

* ¿Los pronósticos parecen realistas y confiables?

* ¿Qué otras alternativas podrían haberse propuesto? (falta)

* ¿Críticas al mejor modelo que encontró en el trabajo actual? 

* Exprese claramente qué recomienda para la serie en cuanto a ajustes globales o locales, según lo realizado hasta el momento. (falta)



Conclusión:

Teniendo como primer criterio de selección los resultados en el análisis de residuales, en segundo lugar los resultados de pronósticos y por último los de ajustes, se concluye que el mejor modelo por el momento, es el modelo 3, este no mostro evidencia en contra de los supuestos(aunque aún no se ha probado el supuesto de independencia ni el de normalidad), además capturó muy bien la dinamica de la serie, este tiene las mejores medidas de pronostico y ajuste, además de que sigue bien la tendencia, estacionalidad y variaciones ciclicas, aunque en algunos pronosticos no parece ser tan realista y confiable debido a que en la mayoria tiende a subestimar los valores y al final de los pronosticos es el modelo más alejado del valor real, por tanto se cree que podria cometer errores en pronosticos ex-ante, por lo tanto puede haberse considerado modelos. 























